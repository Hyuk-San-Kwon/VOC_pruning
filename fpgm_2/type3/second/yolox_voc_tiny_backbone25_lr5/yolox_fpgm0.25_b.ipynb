{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm-4.64.0-py3.8.egg/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_pruning as tp\n",
    "from yolox.models import create_yolox_model\n",
    "\n",
    "model = create_yolox_model(num_classes=20,name = 'yolox_custom',  \n",
    "exp_path = '/workspace/tensorrt/YOLOX/exps/default/custom2/type3/backbone25/yolox_voc_tiny_backbone25_lr5.py',\n",
    "ckpt_path = '/workspace/tensorrt/YOLOX/fpgm_2/type3/second/yolox_voc_tiny_backbone25_lr5/38.01.pth'\n",
    ").cuda()\n",
    "# 1. setup strategy (L1 Norm)\n",
    "strategy = tp.strategy.L1Strategy() # or tp.strategy.RandomStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch_pruning.dependency.DependencyGraph at 0x7fc3bee03fa0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 2. build dependency graph for resnet18\n",
    "DG = tp.DependencyGraph()\n",
    "DG.build_dependency(model, example_inputs=torch.randn(1,3,224,224).cuda())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['backbone.backbone.stem.conv.conv', 'backbone.backbone.dark2[0].conv', 'backbone.backbone.dark2[1].conv1.conv', 'backbone.backbone.dark2[1].conv2.conv', 'backbone.backbone.dark2[1].conv3.conv', 'backbone.backbone.dark2[1].m[0].conv1.conv', 'backbone.backbone.dark2[1].m[0].conv2.conv', 'backbone.backbone.dark3[0].conv', 'backbone.backbone.dark3[1].conv1.conv', 'backbone.backbone.dark3[1].conv2.conv', 'backbone.backbone.dark3[1].conv3.conv', 'backbone.backbone.dark3[1].m[0].conv1.conv', 'backbone.backbone.dark3[1].m[0].conv2.conv', 'backbone.backbone.dark3[1].m[1].conv1.conv', 'backbone.backbone.dark3[1].m[1].conv2.conv', 'backbone.backbone.dark3[1].m[2].conv1.conv', 'backbone.backbone.dark3[1].m[2].conv2.conv', 'backbone.backbone.dark4[0].conv', 'backbone.backbone.dark4[1].conv1.conv', 'backbone.backbone.dark4[1].conv2.conv', 'backbone.backbone.dark4[1].conv3.conv', 'backbone.backbone.dark4[1].m[0].conv1.conv', 'backbone.backbone.dark4[1].m[0].conv2.conv', 'backbone.backbone.dark4[1].m[1].conv1.conv', 'backbone.backbone.dark4[1].m[1].conv2.conv', 'backbone.backbone.dark4[1].m[2].conv1.conv', 'backbone.backbone.dark4[1].m[2].conv2.conv', 'backbone.backbone.dark5[0].conv', 'backbone.backbone.dark5[1].conv1.conv', 'backbone.backbone.dark5[1].conv2.conv', 'backbone.backbone.dark5[2].conv1.conv', 'backbone.backbone.dark5[2].conv2.conv', 'backbone.backbone.dark5[2].conv3.conv', 'backbone.backbone.dark5[2].m[0].conv1.conv', 'backbone.backbone.dark5[2].m[0].conv2.conv', 'backbone.lateral_conv0.conv', 'backbone.C3_p4.conv1.conv', 'backbone.C3_p4.conv2.conv', 'backbone.C3_p4.conv3.conv', 'backbone.C3_p4.m[0].conv1.conv', 'backbone.C3_p4.m[0].conv2.conv', 'backbone.reduce_conv1.conv', 'backbone.C3_p3.conv1.conv', 'backbone.C3_p3.conv2.conv', 'backbone.C3_p3.conv3.conv', 'backbone.C3_p3.m[0].conv1.conv', 'backbone.C3_p3.m[0].conv2.conv', 'backbone.bu_conv2.conv', 'backbone.C3_n3.conv1.conv', 'backbone.C3_n3.conv2.conv', 'backbone.C3_n3.conv3.conv', 'backbone.C3_n3.m[0].conv1.conv', 'backbone.C3_n3.m[0].conv2.conv', 'backbone.bu_conv1.conv', 'backbone.C3_n4.conv1.conv', 'backbone.C3_n4.conv2.conv', 'backbone.C3_n4.conv3.conv', 'backbone.C3_n4.m[0].conv1.conv', 'backbone.C3_n4.m[0].conv2.conv', 'head.cls_convs.0.0.conv', 'head.cls_convs.0.1.conv', 'head.cls_convs.1.0.conv', 'head.cls_convs.1.1.conv', 'head.cls_convs.2[0].conv', 'head.cls_convs.2[1].conv', 'head.reg_convs.0.0.conv', 'head.reg_convs.0.1.conv', 'head.reg_convs.1.0.conv', 'head.reg_convs.1.1.conv', 'head.reg_convs.2[0].conv', 'head.reg_convs.2[1].conv', 'head.cls_preds.0', 'head.cls_preds.1', 'head.cls_preds.2', 'head.reg_preds.0', 'head.reg_preds.1', 'head.reg_preds.2', 'head.obj_preds.0', 'head.obj_preds.1', 'head.obj_preds.2', 'head.stems.0.conv', 'head.stems.1.conv', 'head.stems.2.conv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "temp = []\n",
    "temp2 = list(model.state_dict().keys())\n",
    "num_list = [0,1,2,3]\n",
    "#print(temp2)\n",
    "for i in range(len(temp2)):\n",
    "        if 'bn' in temp2[i]:\n",
    "            continue\n",
    "        if 'weight' in temp2[i]:\n",
    "            temp2[i] = temp2[i].replace('.weight','')\n",
    "            temp2[i] = temp2[i].replace('2.0','2[0]')\n",
    "            temp2[i] = temp2[i].replace('2.1','2[1]')\n",
    "            temp2[i] = temp2[i].replace('3.0','3[0]')\n",
    "            temp2[i] = temp2[i].replace('3.1','3[1]')\n",
    "            temp2[i] = temp2[i].replace('4.0','4[0]')\n",
    "            temp2[i] = temp2[i].replace('4.1','4[1]')\n",
    "            temp2[i] = temp2[i].replace('5.0','5[0]')\n",
    "            temp2[i] = temp2[i].replace('5.1','5[1]')\n",
    "            temp2[i] = temp2[i].replace('5.2','5[2]')\n",
    "            temp2[i] = temp2[i].replace('m.0','m[0]')\n",
    "            temp2[i] = temp2[i].replace('m.1','m[1]')\n",
    "            temp2[i] = temp2[i].replace('m.2','m[2]')\n",
    "            temp.append(temp2[i])\n",
    "\n",
    "print(temp)\n",
    "# backbone 만 프루닝\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOX(\n",
      "  (backbone): YOLOPAFPN(\n",
      "    (backbone): CSPDarknet(\n",
      "      (stem): Focus(\n",
      "        (conv): BaseConv(\n",
      "          (conv): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (dark2): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(24, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): CSPLayer(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv3): BaseConv(\n",
      "            (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dark3): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): CSPLayer(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(96, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(36, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(96, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(36, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv3): BaseConv(\n",
      "            (conv): Conv2d(72, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(36, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(36, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (1): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(36, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(36, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (2): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(36, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(36, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dark4): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): CSPLayer(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(192, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(192, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv3): BaseConv(\n",
      "            (conv): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (1): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (2): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dark5): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): SPPBottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): ModuleList(\n",
      "            (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "            (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
      "            (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): CSPLayer(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(384, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(384, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv3): BaseConv(\n",
      "            (conv): Conv2d(288, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(144, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(144, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(144, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
      "    (lateral_conv0): BaseConv(\n",
      "      (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (C3_p4): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (reduce_conv1): BaseConv(\n",
      "      (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (C3_p3): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bu_conv2): BaseConv(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (C3_n3): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bu_conv1): BaseConv(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (C3_n4): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): YOLOXHead(\n",
      "    (cls_convs): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (reg_convs): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cls_preds): ModuleList(\n",
      "      (0): Conv2d(96, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(96, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): Conv2d(96, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (reg_preds): ModuleList(\n",
      "      (0): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (obj_preds): ModuleList(\n",
      "      (0): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (stems): ModuleList(\n",
      "      (0): BaseConv(\n",
      "        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): BaseConv(\n",
      "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): BaseConv(\n",
      "        (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (l1_loss): L1Loss()\n",
      "    (bcewithlog_loss): BCEWithLogitsLoss()\n",
      "    (iou_loss): IOUloss()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pruning_imagenet import Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mask(model)\n",
    "m.mask_index = [24,27,33,39,45,54,57,63,69,75,90,93,99,102, ] # backbone conv3 30 60 96\n",
    "                           # ,105,108,111,114,117,120,123,141,159] # neck\n",
    "\n",
    "'''\n",
    "m.mask_index = [24,27,30,33,39,45,54,57,60,63,69,75,90,93,99,102,96 \n",
    "                            ,105,108,111,114,117,120,123,141,159,126,129,132,135,138,144,147,150,153,156,162,165,168,171,174, #neck\n",
    "                            231,234,237, #stems\n",
    "                            177,180,183,186,189,192,195,198,201,204,207,210] # head\n",
    "                            '''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.init_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "filter codebook done\n",
      "similar index done\n",
      "mask Ready\n",
      "[30, 60, 96, 105, 108, 111, 114, 117, 120, 123, 141, 159, 126, 129, 132, 135, 138, 144, 147, 150, 153, 156, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210]\n"
     ]
    }
   ],
   "source": [
    "m.init_mask(1, 0.25)\n",
    "print(m.mask_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask Done\n",
      "mask similar Done\n"
     ]
    }
   ],
   "source": [
    "m.do_mask()\n",
    "m.do_similar_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 30, number of nonzero weight is 5184, zero is 1728\n",
      "layer: 60, number of nonzero weight is 20736, zero is 6912\n",
      "layer: 96, number of nonzero weight is 82944, zero is 27648\n",
      "layer: 105, number of nonzero weight is 55296, zero is 18432\n",
      "layer: 108, number of nonzero weight is 27648, zero is 9216\n",
      "layer: 111, number of nonzero weight is 27648, zero is 9216\n",
      "layer: 114, number of nonzero weight is 27648, zero is 9216\n",
      "layer: 117, number of nonzero weight is 6912, zero is 2304\n",
      "layer: 120, number of nonzero weight is 62208, zero is 20736\n",
      "layer: 123, number of nonzero weight is 13824, zero is 4608\n",
      "layer: 126, number of nonzero weight is 6912, zero is 2304\n",
      "layer: 129, number of nonzero weight is 6912, zero is 2304\n",
      "layer: 132, number of nonzero weight is 6912, zero is 2304\n",
      "layer: 135, number of nonzero weight is 1728, zero is 576\n",
      "layer: 138, number of nonzero weight is 15552, zero is 5184\n",
      "layer: 141, number of nonzero weight is 62208, zero is 20736\n",
      "layer: 144, number of nonzero weight is 13824, zero is 4608\n",
      "layer: 147, number of nonzero weight is 13824, zero is 4608\n",
      "layer: 150, number of nonzero weight is 27648, zero is 9216\n",
      "layer: 153, number of nonzero weight is 6912, zero is 2304\n",
      "layer: 156, number of nonzero weight is 62208, zero is 20736\n",
      "layer: 159, number of nonzero weight is 248832, zero is 82944\n",
      "layer: 162, number of nonzero weight is 55296, zero is 18432\n",
      "layer: 165, number of nonzero weight is 55296, zero is 18432\n",
      "layer: 168, number of nonzero weight is 110592, zero is 36864\n",
      "layer: 171, number of nonzero weight is 27648, zero is 9216\n",
      "layer: 174, number of nonzero weight is 248832, zero is 82944\n",
      "layer: 177, number of nonzero weight is 62208, zero is 20736\n",
      "layer: 180, number of nonzero weight is 62208, zero is 20736\n",
      "layer: 183, number of nonzero weight is 62208, zero is 20736\n",
      "layer: 186, number of nonzero weight is 62208, zero is 20736\n",
      "layer: 189, number of nonzero weight is 62208, zero is 20736\n",
      "layer: 192, number of nonzero weight is 62208, zero is 20736\n",
      "layer: 195, number of nonzero weight is 62208, zero is 20736\n",
      "layer: 198, number of nonzero weight is 62208, zero is 20736\n",
      "layer: 201, number of nonzero weight is 62208, zero is 20736\n",
      "layer: 204, number of nonzero weight is 62208, zero is 20736\n",
      "layer: 207, number of nonzero weight is 62208, zero is 20736\n",
      "layer: 210, number of nonzero weight is 62208, zero is 20736\n",
      "[30, 60, 96, 105, 108, 111, 114, 117, 120, 123, 141, 159, 126, 129, 132, 135, 138, 144, 147, 150, 153, 156, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210]\n",
      "{30: tensor([1., 1., 1.,  ..., 0., 0., 0.], device='cuda:0'), 60: tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 96: tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 105: tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 108: tensor([1., 1., 1.,  ..., 0., 0., 0.], device='cuda:0'), 111: tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), 114: tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 117: tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0'), 120: tensor([1., 1., 1.,  ..., 0., 0., 0.], device='cuda:0'), 123: tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0'), 126: tensor([1., 1., 1.,  ..., 0., 0., 0.], device='cuda:0'), 129: tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 132: tensor([1., 1., 1.,  ..., 0., 0., 0.], device='cuda:0'), 135: tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 138: tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0'), 141: tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0'), 144: tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0'), 147: tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0'), 150: tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 153: tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 156: tensor([1., 1., 1.,  ..., 0., 0., 0.], device='cuda:0'), 159: tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 162: tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 165: tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 168: tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 171: tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 174: tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 177: tensor([1., 1., 1.,  ..., 0., 0., 0.], device='cuda:0'), 180: tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 183: tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 186: tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0'), 189: tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 192: tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 195: tensor([1., 1., 1.,  ..., 0., 0., 0.], device='cuda:0'), 198: tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 201: tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 204: tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 207: tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), 210: tensor([1., 1., 1.,  ..., 0., 0., 0.], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "m.if_zero()\n",
    "print(m.mask_index)\n",
    "print(m.similar_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = m.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pruning channel and layer name :  24 , backbone.backbone.stem.conv.conv.weight\n",
      "pruning channel and layer name :  48 , backbone.backbone.dark2.0.conv.weight\n",
      "pruning channel and layer name :  24 , backbone.backbone.dark2.1.conv1.conv.weight\n",
      "pruning channel and layer name :  24 , backbone.backbone.dark2.1.conv2.conv.weight\n",
      "pruning channel and layer name :  48 , backbone.backbone.dark2.1.conv3.conv.weight\n",
      "pruning channel and layer name :  24 , backbone.backbone.dark2.1.m.0.conv1.conv.weight\n",
      "pruning channel and layer name :  24 , backbone.backbone.dark2.1.m.0.conv2.conv.weight\n",
      "pruning channel and layer name :  96 , backbone.backbone.dark3.0.conv.weight\n",
      "pruning channel and layer name :  36 , backbone.backbone.dark3.1.conv1.conv.weight\n",
      "pruning channex index :  5\n",
      "pruning channex index :  12\n",
      "pruning channex index :  13\n",
      "pruning channex index :  14\n",
      "pruning channex index :  23\n",
      "pruning channex index :  25\n",
      "pruning channex index :  26\n",
      "pruning channex index :  31\n",
      "pruning channex index :  33\n",
      "pruning channel and layer name :  36 , backbone.backbone.dark3.1.conv2.conv.weight\n",
      "pruning channex index :  0\n",
      "pruning channex index :  1\n",
      "pruning channex index :  2\n",
      "pruning channex index :  3\n",
      "pruning channex index :  4\n",
      "pruning channex index :  6\n",
      "pruning channex index :  14\n",
      "pruning channex index :  16\n",
      "pruning channex index :  34\n",
      "pruning channel and layer name :  96 , backbone.backbone.dark3.1.conv3.conv.weight\n",
      "pruning channel and layer name :  36 , backbone.backbone.dark3.1.m.0.conv1.conv.weight\n",
      "pruning channex index :  3\n",
      "pruning channex index :  6\n",
      "pruning channex index :  7\n",
      "pruning channex index :  13\n",
      "pruning channex index :  18\n",
      "pruning channex index :  20\n",
      "pruning channex index :  27\n",
      "pruning channex index :  32\n",
      "pruning channex index :  33\n",
      "pruning channel and layer name :  36 , backbone.backbone.dark3.1.m.0.conv2.conv.weight\n",
      "pruning channel and layer name :  36 , backbone.backbone.dark3.1.m.1.conv1.conv.weight\n",
      "pruning channex index :  2\n",
      "pruning channex index :  3\n",
      "pruning channex index :  8\n",
      "pruning channex index :  11\n",
      "pruning channex index :  17\n",
      "pruning channex index :  18\n",
      "pruning channex index :  26\n",
      "pruning channex index :  30\n",
      "pruning channex index :  33\n",
      "pruning channel and layer name :  36 , backbone.backbone.dark3.1.m.1.conv2.conv.weight\n",
      "pruning channel and layer name :  36 , backbone.backbone.dark3.1.m.2.conv1.conv.weight\n",
      "pruning channex index :  1\n",
      "pruning channex index :  4\n",
      "pruning channex index :  10\n",
      "pruning channex index :  12\n",
      "pruning channex index :  16\n",
      "pruning channex index :  18\n",
      "pruning channex index :  24\n",
      "pruning channex index :  28\n",
      "pruning channex index :  34\n",
      "pruning channel and layer name :  36 , backbone.backbone.dark3.1.m.2.conv2.conv.weight\n",
      "pruning channel and layer name :  192 , backbone.backbone.dark4.0.conv.weight\n",
      "pruning channel and layer name :  72 , backbone.backbone.dark4.1.conv1.conv.weight\n",
      "pruning channex index :  4\n",
      "pruning channex index :  11\n",
      "pruning channex index :  12\n",
      "pruning channex index :  13\n",
      "pruning channex index :  17\n",
      "pruning channex index :  19\n",
      "pruning channex index :  21\n",
      "pruning channex index :  23\n",
      "pruning channex index :  24\n",
      "pruning channex index :  32\n",
      "pruning channex index :  33\n",
      "pruning channex index :  40\n",
      "pruning channex index :  42\n",
      "pruning channex index :  48\n",
      "pruning channex index :  52\n",
      "pruning channex index :  54\n",
      "pruning channex index :  64\n",
      "pruning channex index :  67\n",
      "pruning channel and layer name :  72 , backbone.backbone.dark4.1.conv2.conv.weight\n",
      "pruning channex index :  6\n",
      "pruning channex index :  11\n",
      "pruning channex index :  13\n",
      "pruning channex index :  15\n",
      "pruning channex index :  18\n",
      "pruning channex index :  24\n",
      "pruning channex index :  26\n",
      "pruning channex index :  32\n",
      "pruning channex index :  42\n",
      "pruning channex index :  47\n",
      "pruning channex index :  49\n",
      "pruning channex index :  51\n",
      "pruning channex index :  55\n",
      "pruning channex index :  56\n",
      "pruning channex index :  58\n",
      "pruning channex index :  63\n",
      "pruning channex index :  68\n",
      "pruning channex index :  69\n",
      "pruning channel and layer name :  192 , backbone.backbone.dark4.1.conv3.conv.weight\n",
      "pruning channel and layer name :  72 , backbone.backbone.dark4.1.m.0.conv1.conv.weight\n",
      "pruning channex index :  2\n",
      "pruning channex index :  8\n",
      "pruning channex index :  12\n",
      "pruning channex index :  16\n",
      "pruning channex index :  20\n",
      "pruning channex index :  27\n",
      "pruning channex index :  44\n",
      "pruning channex index :  47\n",
      "pruning channex index :  49\n",
      "pruning channex index :  50\n",
      "pruning channex index :  51\n",
      "pruning channex index :  54\n",
      "pruning channex index :  60\n",
      "pruning channex index :  65\n",
      "pruning channex index :  67\n",
      "pruning channex index :  68\n",
      "pruning channex index :  69\n",
      "pruning channex index :  71\n",
      "pruning channel and layer name :  72 , backbone.backbone.dark4.1.m.0.conv2.conv.weight\n",
      "pruning channel and layer name :  72 , backbone.backbone.dark4.1.m.1.conv1.conv.weight\n",
      "pruning channex index :  0\n",
      "pruning channex index :  13\n",
      "pruning channex index :  16\n",
      "pruning channex index :  19\n",
      "pruning channex index :  25\n",
      "pruning channex index :  30\n",
      "pruning channex index :  31\n",
      "pruning channex index :  32\n",
      "pruning channex index :  33\n",
      "pruning channex index :  36\n",
      "pruning channex index :  39\n",
      "pruning channex index :  40\n",
      "pruning channex index :  42\n",
      "pruning channex index :  51\n",
      "pruning channex index :  53\n",
      "pruning channex index :  58\n",
      "pruning channex index :  65\n",
      "pruning channex index :  68\n",
      "pruning channel and layer name :  72 , backbone.backbone.dark4.1.m.1.conv2.conv.weight\n",
      "pruning channel and layer name :  72 , backbone.backbone.dark4.1.m.2.conv1.conv.weight\n",
      "pruning channex index :  9\n",
      "pruning channex index :  10\n",
      "pruning channex index :  16\n",
      "pruning channex index :  17\n",
      "pruning channex index :  18\n",
      "pruning channex index :  20\n",
      "pruning channex index :  23\n",
      "pruning channex index :  28\n",
      "pruning channex index :  30\n",
      "pruning channex index :  31\n",
      "pruning channex index :  43\n",
      "pruning channex index :  44\n",
      "pruning channex index :  52\n",
      "pruning channex index :  56\n",
      "pruning channex index :  59\n",
      "pruning channex index :  64\n",
      "pruning channex index :  67\n",
      "pruning channex index :  71\n",
      "pruning channel and layer name :  72 , backbone.backbone.dark4.1.m.2.conv2.conv.weight\n",
      "pruning channel and layer name :  384 , backbone.backbone.dark5.0.conv.weight\n",
      "pruning channel and layer name :  192 , backbone.backbone.dark5.1.conv1.conv.weight\n",
      "pruning channel and layer name :  384 , backbone.backbone.dark5.1.conv2.conv.weight\n",
      "pruning channel and layer name :  144 , backbone.backbone.dark5.2.conv1.conv.weight\n",
      "pruning channex index :  1\n",
      "pruning channex index :  12\n",
      "pruning channex index :  20\n",
      "pruning channex index :  24\n",
      "pruning channex index :  28\n",
      "pruning channex index :  29\n",
      "pruning channex index :  30\n",
      "pruning channex index :  40\n",
      "pruning channex index :  43\n",
      "pruning channex index :  45\n",
      "pruning channex index :  49\n",
      "pruning channex index :  55\n",
      "pruning channex index :  57\n",
      "pruning channex index :  59\n",
      "pruning channex index :  60\n",
      "pruning channex index :  62\n",
      "pruning channex index :  64\n",
      "pruning channex index :  72\n",
      "pruning channex index :  75\n",
      "pruning channex index :  78\n",
      "pruning channex index :  83\n",
      "pruning channex index :  91\n",
      "pruning channex index :  92\n",
      "pruning channex index :  105\n",
      "pruning channex index :  106\n",
      "pruning channex index :  109\n",
      "pruning channex index :  112\n",
      "pruning channex index :  117\n",
      "pruning channex index :  121\n",
      "pruning channex index :  122\n",
      "pruning channex index :  123\n",
      "pruning channex index :  124\n",
      "pruning channex index :  135\n",
      "pruning channex index :  136\n",
      "pruning channex index :  138\n",
      "pruning channex index :  140\n",
      "pruning channel and layer name :  144 , backbone.backbone.dark5.2.conv2.conv.weight\n",
      "pruning channex index :  3\n",
      "pruning channex index :  4\n",
      "pruning channex index :  5\n",
      "pruning channex index :  7\n",
      "pruning channex index :  9\n",
      "pruning channex index :  10\n",
      "pruning channex index :  11\n",
      "pruning channex index :  20\n",
      "pruning channex index :  21\n",
      "pruning channex index :  25\n",
      "pruning channex index :  43\n",
      "pruning channex index :  44\n",
      "pruning channex index :  46\n",
      "pruning channex index :  47\n",
      "pruning channex index :  54\n",
      "pruning channex index :  59\n",
      "pruning channex index :  65\n",
      "pruning channex index :  66\n",
      "pruning channex index :  67\n",
      "pruning channex index :  70\n",
      "pruning channex index :  74\n",
      "pruning channex index :  75\n",
      "pruning channex index :  78\n",
      "pruning channex index :  83\n",
      "pruning channex index :  88\n",
      "pruning channex index :  91\n",
      "pruning channex index :  95\n",
      "pruning channex index :  102\n",
      "pruning channex index :  103\n",
      "pruning channex index :  110\n",
      "pruning channex index :  111\n",
      "pruning channex index :  116\n",
      "pruning channex index :  123\n",
      "pruning channex index :  134\n",
      "pruning channex index :  138\n",
      "pruning channex index :  139\n",
      "pruning channel and layer name :  384 , backbone.backbone.dark5.2.conv3.conv.weight\n",
      "pruning channel and layer name :  144 , backbone.backbone.dark5.2.m.0.conv1.conv.weight\n",
      "pruning channex index :  6\n",
      "pruning channex index :  8\n",
      "pruning channex index :  11\n",
      "pruning channex index :  13\n",
      "pruning channex index :  17\n",
      "pruning channex index :  21\n",
      "pruning channex index :  24\n",
      "pruning channex index :  29\n",
      "pruning channex index :  34\n",
      "pruning channex index :  38\n",
      "pruning channex index :  39\n",
      "pruning channex index :  40\n",
      "pruning channex index :  41\n",
      "pruning channex index :  50\n",
      "pruning channex index :  59\n",
      "pruning channex index :  65\n",
      "pruning channex index :  66\n",
      "pruning channex index :  71\n",
      "pruning channex index :  75\n",
      "pruning channex index :  76\n",
      "pruning channex index :  81\n",
      "pruning channex index :  82\n",
      "pruning channex index :  83\n",
      "pruning channex index :  96\n",
      "pruning channex index :  103\n",
      "pruning channex index :  105\n",
      "pruning channex index :  106\n",
      "pruning channex index :  110\n",
      "pruning channex index :  113\n",
      "pruning channex index :  118\n",
      "pruning channex index :  120\n",
      "pruning channex index :  129\n",
      "pruning channex index :  130\n",
      "pruning channex index :  135\n",
      "pruning channex index :  140\n",
      "pruning channex index :  143\n",
      "pruning channel and layer name :  144 , backbone.backbone.dark5.2.m.0.conv2.conv.weight\n",
      "pruning channex index :  8\n",
      "pruning channex index :  9\n",
      "pruning channex index :  11\n",
      "pruning channex index :  17\n",
      "pruning channex index :  19\n",
      "pruning channex index :  20\n",
      "pruning channex index :  22\n",
      "pruning channex index :  24\n",
      "pruning channex index :  26\n",
      "pruning channex index :  31\n",
      "pruning channex index :  38\n",
      "pruning channex index :  39\n",
      "pruning channex index :  41\n",
      "pruning channex index :  42\n",
      "pruning channex index :  49\n",
      "pruning channex index :  52\n",
      "pruning channex index :  55\n",
      "pruning channex index :  56\n",
      "pruning channex index :  63\n",
      "pruning channex index :  78\n",
      "pruning channex index :  81\n",
      "pruning channex index :  83\n",
      "pruning channex index :  84\n",
      "pruning channex index :  85\n",
      "pruning channex index :  88\n",
      "pruning channex index :  94\n",
      "pruning channex index :  105\n",
      "pruning channex index :  106\n",
      "pruning channex index :  107\n",
      "pruning channex index :  109\n",
      "pruning channex index :  113\n",
      "pruning channex index :  115\n",
      "pruning channex index :  121\n",
      "pruning channex index :  124\n",
      "pruning channex index :  126\n",
      "pruning channex index :  134\n",
      "pruning channel and layer name :  192 , backbone.lateral_conv0.conv.weight\n",
      "pruning channex index :  10\n",
      "pruning channex index :  16\n",
      "pruning channex index :  17\n",
      "pruning channex index :  18\n",
      "pruning channex index :  32\n",
      "pruning channex index :  33\n",
      "pruning channex index :  35\n",
      "pruning channex index :  43\n",
      "pruning channex index :  51\n",
      "pruning channex index :  53\n",
      "pruning channex index :  54\n",
      "pruning channex index :  61\n",
      "pruning channex index :  63\n",
      "pruning channex index :  67\n",
      "pruning channex index :  69\n",
      "pruning channex index :  73\n",
      "pruning channex index :  74\n",
      "pruning channex index :  78\n",
      "pruning channex index :  81\n",
      "pruning channex index :  84\n",
      "pruning channex index :  85\n",
      "pruning channex index :  101\n",
      "pruning channex index :  102\n",
      "pruning channex index :  104\n",
      "pruning channex index :  107\n",
      "pruning channex index :  111\n",
      "pruning channex index :  120\n",
      "pruning channex index :  121\n",
      "pruning channex index :  133\n",
      "pruning channex index :  135\n",
      "pruning channex index :  137\n",
      "pruning channex index :  139\n",
      "pruning channex index :  140\n",
      "pruning channex index :  142\n",
      "pruning channex index :  144\n",
      "pruning channex index :  146\n",
      "pruning channex index :  155\n",
      "pruning channex index :  162\n",
      "pruning channex index :  164\n",
      "pruning channex index :  172\n",
      "pruning channex index :  175\n",
      "pruning channex index :  176\n",
      "pruning channex index :  178\n",
      "pruning channex index :  181\n",
      "pruning channex index :  182\n",
      "pruning channex index :  184\n",
      "pruning channex index :  185\n",
      "pruning channex index :  186\n",
      "pruning channel and layer name :  96 , backbone.C3_p4.conv1.conv.weight\n",
      "pruning channex index :  11\n",
      "pruning channex index :  12\n",
      "pruning channex index :  15\n",
      "pruning channex index :  17\n",
      "pruning channex index :  23\n",
      "pruning channex index :  28\n",
      "pruning channex index :  35\n",
      "pruning channex index :  36\n",
      "pruning channex index :  37\n",
      "pruning channex index :  38\n",
      "pruning channex index :  40\n",
      "pruning channex index :  42\n",
      "pruning channex index :  46\n",
      "pruning channex index :  56\n",
      "pruning channex index :  58\n",
      "pruning channex index :  66\n",
      "pruning channex index :  70\n",
      "pruning channex index :  73\n",
      "pruning channex index :  82\n",
      "pruning channex index :  84\n",
      "pruning channex index :  85\n",
      "pruning channex index :  86\n",
      "pruning channex index :  88\n",
      "pruning channex index :  95\n",
      "pruning channel and layer name :  96 , backbone.C3_p4.conv2.conv.weight\n",
      "pruning channex index :  0\n",
      "pruning channex index :  10\n",
      "pruning channex index :  13\n",
      "pruning channex index :  15\n",
      "pruning channex index :  16\n",
      "pruning channex index :  26\n",
      "pruning channex index :  28\n",
      "pruning channex index :  41\n",
      "pruning channex index :  44\n",
      "pruning channex index :  45\n",
      "pruning channex index :  47\n",
      "pruning channex index :  48\n",
      "pruning channex index :  57\n",
      "pruning channex index :  59\n",
      "pruning channex index :  64\n",
      "pruning channex index :  65\n",
      "pruning channex index :  66\n",
      "pruning channex index :  70\n",
      "pruning channex index :  76\n",
      "pruning channex index :  81\n",
      "pruning channex index :  85\n",
      "pruning channex index :  87\n",
      "pruning channex index :  88\n",
      "pruning channex index :  95\n",
      "pruning channel and layer name :  192 , backbone.C3_p4.conv3.conv.weight\n",
      "pruning channel and layer name :  96 , backbone.C3_p4.m.0.conv1.conv.weight\n",
      "pruning channex index :  0\n",
      "pruning channex index :  3\n",
      "pruning channex index :  6\n",
      "pruning channex index :  9\n",
      "pruning channex index :  13\n",
      "pruning channex index :  17\n",
      "pruning channex index :  21\n",
      "pruning channex index :  23\n",
      "pruning channex index :  47\n",
      "pruning channex index :  52\n",
      "pruning channex index :  53\n",
      "pruning channex index :  57\n",
      "pruning channex index :  61\n",
      "pruning channex index :  66\n",
      "pruning channex index :  67\n",
      "pruning channex index :  77\n",
      "pruning channex index :  80\n",
      "pruning channex index :  81\n",
      "pruning channex index :  82\n",
      "pruning channex index :  88\n",
      "pruning channex index :  89\n",
      "pruning channex index :  90\n",
      "pruning channex index :  92\n",
      "pruning channex index :  94\n",
      "pruning channel and layer name :  96 , backbone.C3_p4.m.0.conv2.conv.weight\n",
      "pruning channex index :  2\n",
      "pruning channex index :  6\n",
      "pruning channex index :  11\n",
      "pruning channex index :  12\n",
      "pruning channex index :  19\n",
      "pruning channex index :  20\n",
      "pruning channex index :  22\n",
      "pruning channex index :  24\n",
      "pruning channex index :  27\n",
      "pruning channex index :  28\n",
      "pruning channex index :  29\n",
      "pruning channex index :  44\n",
      "pruning channex index :  57\n",
      "pruning channex index :  63\n",
      "pruning channex index :  65\n",
      "pruning channex index :  66\n",
      "pruning channex index :  67\n",
      "pruning channex index :  74\n",
      "pruning channex index :  76\n",
      "pruning channex index :  79\n",
      "pruning channex index :  80\n",
      "pruning channex index :  81\n",
      "pruning channex index :  88\n",
      "pruning channex index :  95\n",
      "pruning channel and layer name :  96 , backbone.reduce_conv1.conv.weight\n",
      "pruning channex index :  0\n",
      "pruning channex index :  5\n",
      "pruning channex index :  11\n",
      "pruning channex index :  16\n",
      "pruning channex index :  20\n",
      "pruning channex index :  22\n",
      "pruning channex index :  31\n",
      "pruning channex index :  34\n",
      "pruning channex index :  40\n",
      "pruning channex index :  46\n",
      "pruning channex index :  51\n",
      "pruning channex index :  61\n",
      "pruning channex index :  63\n",
      "pruning channex index :  65\n",
      "pruning channex index :  67\n",
      "pruning channex index :  68\n",
      "pruning channex index :  73\n",
      "pruning channex index :  76\n",
      "pruning channex index :  77\n",
      "pruning channex index :  78\n",
      "pruning channex index :  79\n",
      "pruning channex index :  89\n",
      "pruning channex index :  92\n",
      "pruning channex index :  94\n",
      "pruning channel and layer name :  48 , backbone.C3_p3.conv1.conv.weight\n",
      "pruning channex index :  5\n",
      "pruning channex index :  9\n",
      "pruning channex index :  12\n",
      "pruning channex index :  21\n",
      "pruning channex index :  31\n",
      "pruning channex index :  34\n",
      "pruning channex index :  35\n",
      "pruning channex index :  39\n",
      "pruning channex index :  40\n",
      "pruning channex index :  43\n",
      "pruning channex index :  45\n",
      "pruning channex index :  47\n",
      "pruning channel and layer name :  48 , backbone.C3_p3.conv2.conv.weight\n",
      "pruning channex index :  2\n",
      "pruning channex index :  11\n",
      "pruning channex index :  13\n",
      "pruning channex index :  16\n",
      "pruning channex index :  17\n",
      "pruning channex index :  20\n",
      "pruning channex index :  23\n",
      "pruning channex index :  25\n",
      "pruning channex index :  30\n",
      "pruning channex index :  32\n",
      "pruning channex index :  42\n",
      "pruning channex index :  43\n",
      "pruning channel and layer name :  96 , backbone.C3_p3.conv3.conv.weight\n",
      "pruning channel and layer name :  48 , backbone.C3_p3.m.0.conv1.conv.weight\n",
      "pruning channex index :  2\n",
      "pruning channex index :  3\n",
      "pruning channex index :  9\n",
      "pruning channex index :  15\n",
      "pruning channex index :  17\n",
      "pruning channex index :  20\n",
      "pruning channex index :  24\n",
      "pruning channex index :  26\n",
      "pruning channex index :  28\n",
      "pruning channex index :  35\n",
      "pruning channex index :  38\n",
      "pruning channex index :  45\n",
      "pruning channel and layer name :  48 , backbone.C3_p3.m.0.conv2.conv.weight\n",
      "pruning channex index :  0\n",
      "pruning channex index :  1\n",
      "pruning channex index :  5\n",
      "pruning channex index :  14\n",
      "pruning channex index :  19\n",
      "pruning channex index :  28\n",
      "pruning channex index :  32\n",
      "pruning channex index :  40\n",
      "pruning channex index :  42\n",
      "pruning channex index :  43\n",
      "pruning channex index :  45\n",
      "pruning channex index :  46\n",
      "pruning channel and layer name :  96 , backbone.bu_conv2.conv.weight\n",
      "pruning channex index :  0\n",
      "pruning channex index :  2\n",
      "pruning channex index :  5\n",
      "pruning channex index :  12\n",
      "pruning channex index :  13\n",
      "pruning channex index :  14\n",
      "pruning channex index :  19\n",
      "pruning channex index :  22\n",
      "pruning channex index :  26\n",
      "pruning channex index :  33\n",
      "pruning channex index :  41\n",
      "pruning channex index :  43\n",
      "pruning channex index :  44\n",
      "pruning channex index :  52\n",
      "pruning channex index :  54\n",
      "pruning channex index :  56\n",
      "pruning channex index :  63\n",
      "pruning channex index :  66\n",
      "pruning channex index :  68\n",
      "pruning channex index :  72\n",
      "pruning channex index :  78\n",
      "pruning channex index :  82\n",
      "pruning channex index :  85\n",
      "pruning channex index :  87\n",
      "pruning channel and layer name :  96 , backbone.C3_n3.conv1.conv.weight\n",
      "pruning channex index :  0\n",
      "pruning channex index :  3\n",
      "pruning channex index :  7\n",
      "pruning channex index :  8\n",
      "pruning channex index :  9\n",
      "pruning channex index :  17\n",
      "pruning channex index :  18\n",
      "pruning channex index :  21\n",
      "pruning channex index :  26\n",
      "pruning channex index :  32\n",
      "pruning channex index :  40\n",
      "pruning channex index :  54\n",
      "pruning channex index :  60\n",
      "pruning channex index :  64\n",
      "pruning channex index :  65\n",
      "pruning channex index :  69\n",
      "pruning channex index :  74\n",
      "pruning channex index :  82\n",
      "pruning channex index :  87\n",
      "pruning channex index :  89\n",
      "pruning channex index :  90\n",
      "pruning channex index :  91\n",
      "pruning channex index :  93\n",
      "pruning channex index :  94\n",
      "pruning channel and layer name :  96 , backbone.C3_n3.conv2.conv.weight\n",
      "pruning channex index :  0\n",
      "pruning channex index :  1\n",
      "pruning channex index :  4\n",
      "pruning channex index :  5\n",
      "pruning channex index :  6\n",
      "pruning channex index :  7\n",
      "pruning channex index :  14\n",
      "pruning channex index :  27\n",
      "pruning channex index :  33\n",
      "pruning channex index :  35\n",
      "pruning channex index :  40\n",
      "pruning channex index :  41\n",
      "pruning channex index :  47\n",
      "pruning channex index :  52\n",
      "pruning channex index :  54\n",
      "pruning channex index :  67\n",
      "pruning channex index :  69\n",
      "pruning channex index :  70\n",
      "pruning channex index :  71\n",
      "pruning channex index :  74\n",
      "pruning channex index :  80\n",
      "pruning channex index :  89\n",
      "pruning channex index :  90\n",
      "pruning channex index :  92\n",
      "pruning channel and layer name :  192 , backbone.C3_n3.conv3.conv.weight\n",
      "pruning channel and layer name :  96 , backbone.C3_n3.m.0.conv1.conv.weight\n",
      "pruning channex index :  4\n",
      "pruning channex index :  8\n",
      "pruning channex index :  16\n",
      "pruning channex index :  20\n",
      "pruning channex index :  22\n",
      "pruning channex index :  28\n",
      "pruning channex index :  31\n",
      "pruning channex index :  37\n",
      "pruning channex index :  47\n",
      "pruning channex index :  51\n",
      "pruning channex index :  52\n",
      "pruning channex index :  63\n",
      "pruning channex index :  66\n",
      "pruning channex index :  67\n",
      "pruning channex index :  70\n",
      "pruning channex index :  72\n",
      "pruning channex index :  73\n",
      "pruning channex index :  74\n",
      "pruning channex index :  81\n",
      "pruning channex index :  83\n",
      "pruning channex index :  85\n",
      "pruning channex index :  88\n",
      "pruning channex index :  90\n",
      "pruning channex index :  91\n",
      "pruning channel and layer name :  96 , backbone.C3_n3.m.0.conv2.conv.weight\n",
      "pruning channex index :  2\n",
      "pruning channex index :  4\n",
      "pruning channex index :  6\n",
      "pruning channex index :  10\n",
      "pruning channex index :  11\n",
      "pruning channex index :  13\n",
      "pruning channex index :  16\n",
      "pruning channex index :  19\n",
      "pruning channex index :  22\n",
      "pruning channex index :  25\n",
      "pruning channex index :  27\n",
      "pruning channex index :  31\n",
      "pruning channex index :  33\n",
      "pruning channex index :  37\n",
      "pruning channex index :  41\n",
      "pruning channex index :  53\n",
      "pruning channex index :  54\n",
      "pruning channex index :  58\n",
      "pruning channex index :  62\n",
      "pruning channex index :  68\n",
      "pruning channex index :  85\n",
      "pruning channex index :  87\n",
      "pruning channex index :  92\n",
      "pruning channex index :  95\n",
      "pruning channel and layer name :  192 , backbone.bu_conv1.conv.weight\n",
      "pruning channex index :  11\n",
      "pruning channex index :  13\n",
      "pruning channex index :  14\n",
      "pruning channex index :  16\n",
      "pruning channex index :  18\n",
      "pruning channex index :  20\n",
      "pruning channex index :  26\n",
      "pruning channex index :  28\n",
      "pruning channex index :  29\n",
      "pruning channex index :  30\n",
      "pruning channex index :  40\n",
      "pruning channex index :  42\n",
      "pruning channex index :  43\n",
      "pruning channex index :  48\n",
      "pruning channex index :  49\n",
      "pruning channex index :  50\n",
      "pruning channex index :  54\n",
      "pruning channex index :  60\n",
      "pruning channex index :  64\n",
      "pruning channex index :  73\n",
      "pruning channex index :  76\n",
      "pruning channex index :  80\n",
      "pruning channex index :  83\n",
      "pruning channex index :  90\n",
      "pruning channex index :  94\n",
      "pruning channex index :  96\n",
      "pruning channex index :  100\n",
      "pruning channex index :  103\n",
      "pruning channex index :  105\n",
      "pruning channex index :  106\n",
      "pruning channex index :  117\n",
      "pruning channex index :  122\n",
      "pruning channex index :  123\n",
      "pruning channex index :  138\n",
      "pruning channex index :  140\n",
      "pruning channex index :  145\n",
      "pruning channex index :  149\n",
      "pruning channex index :  164\n",
      "pruning channex index :  166\n",
      "pruning channex index :  172\n",
      "pruning channex index :  175\n",
      "pruning channex index :  176\n",
      "pruning channex index :  179\n",
      "pruning channex index :  180\n",
      "pruning channex index :  182\n",
      "pruning channex index :  184\n",
      "pruning channex index :  188\n",
      "pruning channex index :  189\n",
      "pruning channel and layer name :  192 , backbone.C3_n4.conv1.conv.weight\n",
      "pruning channex index :  5\n",
      "pruning channex index :  6\n",
      "pruning channex index :  7\n",
      "pruning channex index :  10\n",
      "pruning channex index :  13\n",
      "pruning channex index :  18\n",
      "pruning channex index :  19\n",
      "pruning channex index :  21\n",
      "pruning channex index :  26\n",
      "pruning channex index :  34\n",
      "pruning channex index :  35\n",
      "pruning channex index :  37\n",
      "pruning channex index :  38\n",
      "pruning channex index :  40\n",
      "pruning channex index :  41\n",
      "pruning channex index :  42\n",
      "pruning channex index :  48\n",
      "pruning channex index :  52\n",
      "pruning channex index :  61\n",
      "pruning channex index :  62\n",
      "pruning channex index :  66\n",
      "pruning channex index :  75\n",
      "pruning channex index :  84\n",
      "pruning channex index :  88\n",
      "pruning channex index :  93\n",
      "pruning channex index :  95\n",
      "pruning channex index :  103\n",
      "pruning channex index :  104\n",
      "pruning channex index :  110\n",
      "pruning channex index :  118\n",
      "pruning channex index :  120\n",
      "pruning channex index :  125\n",
      "pruning channex index :  130\n",
      "pruning channex index :  133\n",
      "pruning channex index :  134\n",
      "pruning channex index :  135\n",
      "pruning channex index :  137\n",
      "pruning channex index :  143\n",
      "pruning channex index :  144\n",
      "pruning channex index :  145\n",
      "pruning channex index :  147\n",
      "pruning channex index :  148\n",
      "pruning channex index :  149\n",
      "pruning channex index :  153\n",
      "pruning channex index :  169\n",
      "pruning channex index :  174\n",
      "pruning channex index :  188\n",
      "pruning channex index :  189\n",
      "pruning channel and layer name :  192 , backbone.C3_n4.conv2.conv.weight\n",
      "pruning channex index :  1\n",
      "pruning channex index :  11\n",
      "pruning channex index :  13\n",
      "pruning channex index :  20\n",
      "pruning channex index :  23\n",
      "pruning channex index :  35\n",
      "pruning channex index :  37\n",
      "pruning channex index :  38\n",
      "pruning channex index :  42\n",
      "pruning channex index :  46\n",
      "pruning channex index :  47\n",
      "pruning channex index :  48\n",
      "pruning channex index :  49\n",
      "pruning channex index :  51\n",
      "pruning channex index :  52\n",
      "pruning channex index :  58\n",
      "pruning channex index :  59\n",
      "pruning channex index :  66\n",
      "pruning channex index :  75\n",
      "pruning channex index :  79\n",
      "pruning channex index :  83\n",
      "pruning channex index :  86\n",
      "pruning channex index :  88\n",
      "pruning channex index :  92\n",
      "pruning channex index :  102\n",
      "pruning channex index :  108\n",
      "pruning channex index :  109\n",
      "pruning channex index :  117\n",
      "pruning channex index :  119\n",
      "pruning channex index :  121\n",
      "pruning channex index :  125\n",
      "pruning channex index :  126\n",
      "pruning channex index :  127\n",
      "pruning channex index :  128\n",
      "pruning channex index :  129\n",
      "pruning channex index :  130\n",
      "pruning channex index :  131\n",
      "pruning channex index :  135\n",
      "pruning channex index :  139\n",
      "pruning channex index :  141\n",
      "pruning channex index :  145\n",
      "pruning channex index :  146\n",
      "pruning channex index :  151\n",
      "pruning channex index :  160\n",
      "pruning channex index :  176\n",
      "pruning channex index :  178\n",
      "pruning channex index :  180\n",
      "pruning channex index :  190\n",
      "pruning channel and layer name :  384 , backbone.C3_n4.conv3.conv.weight\n",
      "pruning channel and layer name :  192 , backbone.C3_n4.m.0.conv1.conv.weight\n",
      "pruning channex index :  2\n",
      "pruning channex index :  6\n",
      "pruning channex index :  7\n",
      "pruning channex index :  10\n",
      "pruning channex index :  12\n",
      "pruning channex index :  18\n",
      "pruning channex index :  26\n",
      "pruning channex index :  33\n",
      "pruning channex index :  36\n",
      "pruning channex index :  44\n",
      "pruning channex index :  48\n",
      "pruning channex index :  53\n",
      "pruning channex index :  55\n",
      "pruning channex index :  58\n",
      "pruning channex index :  59\n",
      "pruning channex index :  60\n",
      "pruning channex index :  61\n",
      "pruning channex index :  62\n",
      "pruning channex index :  71\n",
      "pruning channex index :  73\n",
      "pruning channex index :  74\n",
      "pruning channex index :  75\n",
      "pruning channex index :  77\n",
      "pruning channex index :  83\n",
      "pruning channex index :  85\n",
      "pruning channex index :  96\n",
      "pruning channex index :  99\n",
      "pruning channex index :  112\n",
      "pruning channex index :  122\n",
      "pruning channex index :  128\n",
      "pruning channex index :  130\n",
      "pruning channex index :  132\n",
      "pruning channex index :  135\n",
      "pruning channex index :  137\n",
      "pruning channex index :  140\n",
      "pruning channex index :  142\n",
      "pruning channex index :  144\n",
      "pruning channex index :  146\n",
      "pruning channex index :  159\n",
      "pruning channex index :  164\n",
      "pruning channex index :  171\n",
      "pruning channex index :  172\n",
      "pruning channex index :  177\n",
      "pruning channex index :  180\n",
      "pruning channex index :  181\n",
      "pruning channex index :  184\n",
      "pruning channex index :  185\n",
      "pruning channex index :  187\n",
      "pruning channel and layer name :  192 , backbone.C3_n4.m.0.conv2.conv.weight\n",
      "pruning channex index :  1\n",
      "pruning channex index :  14\n",
      "pruning channex index :  16\n",
      "pruning channex index :  19\n",
      "pruning channex index :  20\n",
      "pruning channex index :  25\n",
      "pruning channex index :  32\n",
      "pruning channex index :  33\n",
      "pruning channex index :  46\n",
      "pruning channex index :  54\n",
      "pruning channex index :  58\n",
      "pruning channex index :  61\n",
      "pruning channex index :  62\n",
      "pruning channex index :  66\n",
      "pruning channex index :  67\n",
      "pruning channex index :  72\n",
      "pruning channex index :  79\n",
      "pruning channex index :  82\n",
      "pruning channex index :  84\n",
      "pruning channex index :  89\n",
      "pruning channex index :  93\n",
      "pruning channex index :  95\n",
      "pruning channex index :  97\n",
      "pruning channex index :  105\n",
      "pruning channex index :  107\n",
      "pruning channex index :  108\n",
      "pruning channex index :  111\n",
      "pruning channex index :  116\n",
      "pruning channex index :  120\n",
      "pruning channex index :  127\n",
      "pruning channex index :  129\n",
      "pruning channex index :  137\n",
      "pruning channex index :  142\n",
      "pruning channex index :  144\n",
      "pruning channex index :  145\n",
      "pruning channex index :  146\n",
      "pruning channex index :  152\n",
      "pruning channex index :  154\n",
      "pruning channex index :  164\n",
      "pruning channex index :  165\n",
      "pruning channex index :  166\n",
      "pruning channex index :  176\n",
      "pruning channex index :  180\n",
      "pruning channex index :  182\n",
      "pruning channex index :  183\n",
      "pruning channex index :  185\n",
      "pruning channex index :  186\n",
      "pruning channex index :  189\n",
      "pruning channel and layer name :  96 , head.cls_convs.0.0.conv.weight\n",
      "pruning channex index :  6\n",
      "pruning channex index :  10\n",
      "pruning channex index :  11\n",
      "pruning channex index :  14\n",
      "pruning channex index :  22\n",
      "pruning channex index :  28\n",
      "pruning channex index :  30\n",
      "pruning channex index :  35\n",
      "pruning channex index :  45\n",
      "pruning channex index :  46\n",
      "pruning channex index :  47\n",
      "pruning channex index :  53\n",
      "pruning channex index :  56\n",
      "pruning channex index :  59\n",
      "pruning channex index :  62\n",
      "pruning channex index :  69\n",
      "pruning channex index :  70\n",
      "pruning channex index :  74\n",
      "pruning channex index :  77\n",
      "pruning channex index :  80\n",
      "pruning channex index :  91\n",
      "pruning channex index :  92\n",
      "pruning channex index :  94\n",
      "pruning channex index :  95\n",
      "pruning channel and layer name :  96 , head.cls_convs.0.1.conv.weight\n",
      "pruning channex index :  3\n",
      "pruning channex index :  6\n",
      "pruning channex index :  12\n",
      "pruning channex index :  13\n",
      "pruning channex index :  24\n",
      "pruning channex index :  26\n",
      "pruning channex index :  35\n",
      "pruning channex index :  36\n",
      "pruning channex index :  39\n",
      "pruning channex index :  41\n",
      "pruning channex index :  44\n",
      "pruning channex index :  45\n",
      "pruning channex index :  49\n",
      "pruning channex index :  52\n",
      "pruning channex index :  59\n",
      "pruning channex index :  60\n",
      "pruning channex index :  63\n",
      "pruning channex index :  64\n",
      "pruning channex index :  67\n",
      "pruning channex index :  71\n",
      "pruning channex index :  79\n",
      "pruning channex index :  85\n",
      "pruning channex index :  89\n",
      "pruning channex index :  92\n",
      "pruning channel and layer name :  96 , head.cls_convs.1.0.conv.weight\n",
      "pruning channex index :  1\n",
      "pruning channex index :  13\n",
      "pruning channex index :  16\n",
      "pruning channex index :  25\n",
      "pruning channex index :  27\n",
      "pruning channex index :  31\n",
      "pruning channex index :  34\n",
      "pruning channex index :  37\n",
      "pruning channex index :  38\n",
      "pruning channex index :  44\n",
      "pruning channex index :  49\n",
      "pruning channex index :  51\n",
      "pruning channex index :  56\n",
      "pruning channex index :  61\n",
      "pruning channex index :  62\n",
      "pruning channex index :  63\n",
      "pruning channex index :  68\n",
      "pruning channex index :  71\n",
      "pruning channex index :  77\n",
      "pruning channex index :  78\n",
      "pruning channex index :  90\n",
      "pruning channex index :  91\n",
      "pruning channex index :  93\n",
      "pruning channex index :  94\n",
      "pruning channel and layer name :  96 , head.cls_convs.1.1.conv.weight\n",
      "pruning channex index :  0\n",
      "pruning channex index :  1\n",
      "pruning channex index :  3\n",
      "pruning channex index :  7\n",
      "pruning channex index :  14\n",
      "pruning channex index :  25\n",
      "pruning channex index :  26\n",
      "pruning channex index :  29\n",
      "pruning channex index :  31\n",
      "pruning channex index :  33\n",
      "pruning channex index :  38\n",
      "pruning channex index :  39\n",
      "pruning channex index :  40\n",
      "pruning channex index :  41\n",
      "pruning channex index :  47\n",
      "pruning channex index :  49\n",
      "pruning channex index :  50\n",
      "pruning channex index :  58\n",
      "pruning channex index :  59\n",
      "pruning channex index :  71\n",
      "pruning channex index :  72\n",
      "pruning channex index :  86\n",
      "pruning channex index :  87\n",
      "pruning channex index :  93\n",
      "pruning channel and layer name :  96 , head.cls_convs.2.0.conv.weight\n",
      "pruning channex index :  2\n",
      "pruning channex index :  7\n",
      "pruning channex index :  15\n",
      "pruning channex index :  17\n",
      "pruning channex index :  19\n",
      "pruning channex index :  20\n",
      "pruning channex index :  21\n",
      "pruning channex index :  22\n",
      "pruning channex index :  27\n",
      "pruning channex index :  28\n",
      "pruning channex index :  29\n",
      "pruning channex index :  31\n",
      "pruning channex index :  40\n",
      "pruning channex index :  44\n",
      "pruning channex index :  45\n",
      "pruning channex index :  47\n",
      "pruning channex index :  53\n",
      "pruning channex index :  62\n",
      "pruning channex index :  70\n",
      "pruning channex index :  72\n",
      "pruning channex index :  73\n",
      "pruning channex index :  79\n",
      "pruning channex index :  85\n",
      "pruning channex index :  92\n",
      "pruning channel and layer name :  96 , head.cls_convs.2.1.conv.weight\n",
      "pruning channex index :  8\n",
      "pruning channex index :  10\n",
      "pruning channex index :  11\n",
      "pruning channex index :  14\n",
      "pruning channex index :  25\n",
      "pruning channex index :  27\n",
      "pruning channex index :  28\n",
      "pruning channex index :  29\n",
      "pruning channex index :  31\n",
      "pruning channex index :  37\n",
      "pruning channex index :  40\n",
      "pruning channex index :  43\n",
      "pruning channex index :  46\n",
      "pruning channex index :  54\n",
      "pruning channex index :  56\n",
      "pruning channex index :  59\n",
      "pruning channex index :  60\n",
      "pruning channex index :  68\n",
      "pruning channex index :  74\n",
      "pruning channex index :  80\n",
      "pruning channex index :  83\n",
      "pruning channex index :  84\n",
      "pruning channex index :  91\n",
      "pruning channex index :  92\n",
      "pruning channel and layer name :  96 , head.reg_convs.0.0.conv.weight\n",
      "pruning channex index :  2\n",
      "pruning channex index :  13\n",
      "pruning channex index :  23\n",
      "pruning channex index :  25\n",
      "pruning channex index :  31\n",
      "pruning channex index :  33\n",
      "pruning channex index :  34\n",
      "pruning channex index :  36\n",
      "pruning channex index :  47\n",
      "pruning channex index :  49\n",
      "pruning channex index :  53\n",
      "pruning channex index :  55\n",
      "pruning channex index :  67\n",
      "pruning channex index :  69\n",
      "pruning channex index :  72\n",
      "pruning channex index :  76\n",
      "pruning channex index :  79\n",
      "pruning channex index :  80\n",
      "pruning channex index :  81\n",
      "pruning channex index :  82\n",
      "pruning channex index :  90\n",
      "pruning channex index :  92\n",
      "pruning channex index :  93\n",
      "pruning channex index :  95\n",
      "pruning channel and layer name :  96 , head.reg_convs.0.1.conv.weight\n",
      "pruning channex index :  3\n",
      "pruning channex index :  4\n",
      "pruning channex index :  16\n",
      "pruning channex index :  21\n",
      "pruning channex index :  22\n",
      "pruning channex index :  23\n",
      "pruning channex index :  26\n",
      "pruning channex index :  34\n",
      "pruning channex index :  35\n",
      "pruning channex index :  40\n",
      "pruning channex index :  41\n",
      "pruning channex index :  47\n",
      "pruning channex index :  48\n",
      "pruning channex index :  51\n",
      "pruning channex index :  56\n",
      "pruning channex index :  58\n",
      "pruning channex index :  59\n",
      "pruning channex index :  63\n",
      "pruning channex index :  64\n",
      "pruning channex index :  69\n",
      "pruning channex index :  72\n",
      "pruning channex index :  80\n",
      "pruning channex index :  82\n",
      "pruning channex index :  90\n",
      "pruning channel and layer name :  96 , head.reg_convs.1.0.conv.weight\n",
      "pruning channex index :  1\n",
      "pruning channex index :  5\n",
      "pruning channex index :  11\n",
      "pruning channex index :  15\n",
      "pruning channex index :  21\n",
      "pruning channex index :  22\n",
      "pruning channex index :  23\n",
      "pruning channex index :  26\n",
      "pruning channex index :  27\n",
      "pruning channex index :  32\n",
      "pruning channex index :  39\n",
      "pruning channex index :  42\n",
      "pruning channex index :  49\n",
      "pruning channex index :  51\n",
      "pruning channex index :  65\n",
      "pruning channex index :  66\n",
      "pruning channex index :  68\n",
      "pruning channex index :  75\n",
      "pruning channex index :  76\n",
      "pruning channex index :  82\n",
      "pruning channex index :  87\n",
      "pruning channex index :  88\n",
      "pruning channex index :  91\n",
      "pruning channex index :  94\n",
      "pruning channel and layer name :  96 , head.reg_convs.1.1.conv.weight\n",
      "pruning channex index :  12\n",
      "pruning channex index :  16\n",
      "pruning channex index :  17\n",
      "pruning channex index :  29\n",
      "pruning channex index :  32\n",
      "pruning channex index :  35\n",
      "pruning channex index :  38\n",
      "pruning channex index :  41\n",
      "pruning channex index :  45\n",
      "pruning channex index :  50\n",
      "pruning channex index :  51\n",
      "pruning channex index :  53\n",
      "pruning channex index :  56\n",
      "pruning channex index :  62\n",
      "pruning channex index :  69\n",
      "pruning channex index :  70\n",
      "pruning channex index :  71\n",
      "pruning channex index :  75\n",
      "pruning channex index :  77\n",
      "pruning channex index :  81\n",
      "pruning channex index :  82\n",
      "pruning channex index :  86\n",
      "pruning channex index :  88\n",
      "pruning channex index :  91\n",
      "pruning channel and layer name :  96 , head.reg_convs.2.0.conv.weight\n",
      "pruning channex index :  6\n",
      "pruning channex index :  8\n",
      "pruning channex index :  9\n",
      "pruning channex index :  13\n",
      "pruning channex index :  16\n",
      "pruning channex index :  20\n",
      "pruning channex index :  24\n",
      "pruning channex index :  29\n",
      "pruning channex index :  33\n",
      "pruning channex index :  37\n",
      "pruning channex index :  41\n",
      "pruning channex index :  46\n",
      "pruning channex index :  50\n",
      "pruning channex index :  52\n",
      "pruning channex index :  53\n",
      "pruning channex index :  54\n",
      "pruning channex index :  59\n",
      "pruning channex index :  61\n",
      "pruning channex index :  70\n",
      "pruning channex index :  73\n",
      "pruning channex index :  77\n",
      "pruning channex index :  82\n",
      "pruning channex index :  87\n",
      "pruning channex index :  91\n",
      "pruning channel and layer name :  96 , head.reg_convs.2.1.conv.weight\n",
      "pruning channex index :  1\n",
      "pruning channex index :  5\n",
      "pruning channex index :  11\n",
      "pruning channex index :  17\n",
      "pruning channex index :  19\n",
      "pruning channex index :  20\n",
      "pruning channex index :  21\n",
      "pruning channex index :  26\n",
      "pruning channex index :  27\n",
      "pruning channex index :  29\n",
      "pruning channex index :  32\n",
      "pruning channex index :  35\n",
      "pruning channex index :  38\n",
      "pruning channex index :  44\n",
      "pruning channex index :  52\n",
      "pruning channex index :  67\n",
      "pruning channex index :  68\n",
      "pruning channex index :  70\n",
      "pruning channex index :  72\n",
      "pruning channex index :  82\n",
      "pruning channex index :  86\n",
      "pruning channex index :  89\n",
      "pruning channex index :  94\n",
      "pruning channex index :  95\n",
      "pruning channel and layer name :  20 , head.cls_preds.0.weight\n",
      "pruning channel and layer name :  20 , head.cls_preds.1.weight\n",
      "pruning channel and layer name :  20 , head.cls_preds.2.weight\n",
      "pruning channel and layer name :  4 , head.reg_preds.0.weight\n",
      "pruning channel and layer name :  4 , head.reg_preds.1.weight\n",
      "pruning channel and layer name :  4 , head.reg_preds.2.weight\n",
      "pruning channel and layer name :  1 , head.obj_preds.0.weight\n",
      "pruning channel and layer name :  1 , head.obj_preds.1.weight\n",
      "pruning channel and layer name :  1 , head.obj_preds.2.weight\n",
      "pruning channel and layer name :  96 , head.stems.0.conv.weight\n",
      "pruning channel and layer name :  96 , head.stems.1.conv.weight\n",
      "pruning channel and layer name :  96 , head.stems.2.conv.weight\n"
     ]
    }
   ],
   "source": [
    "dict ={}\n",
    "\n",
    "\n",
    "for key, value in model.state_dict().items():\n",
    "    temp = []\n",
    "    if len(value.shape) ==4:\n",
    "        print('pruning channel and layer name : ',len(value),',', key)\n",
    "        for i in range(len(value)):\n",
    "            if 'conv3' in key:\n",
    "                continue\n",
    "            if value[i].sum() == 0: \n",
    "                print('pruning channex index : ', i)\n",
    "                #temp = torch.norm(value.view(len(value), -1) , p= 1, dim=1)\n",
    "                #print(temp)\n",
    "                #dict[key].append(i)\n",
    "                temp.append(i)\n",
    "    if temp:   \n",
    "        dict[key]  = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'backbone.backbone.dark3.1.conv1.conv.weight': [5, 12, 13, 14, 23, 25, 26, 31, 33], 'backbone.backbone.dark3.1.conv2.conv.weight': [0, 1, 2, 3, 4, 6, 14, 16, 34], 'backbone.backbone.dark3.1.m.0.conv1.conv.weight': [3, 6, 7, 13, 18, 20, 27, 32, 33], 'backbone.backbone.dark3.1.m.1.conv1.conv.weight': [2, 3, 8, 11, 17, 18, 26, 30, 33], 'backbone.backbone.dark3.1.m.2.conv1.conv.weight': [1, 4, 10, 12, 16, 18, 24, 28, 34], 'backbone.backbone.dark4.1.conv1.conv.weight': [4, 11, 12, 13, 17, 19, 21, 23, 24, 32, 33, 40, 42, 48, 52, 54, 64, 67], 'backbone.backbone.dark4.1.conv2.conv.weight': [6, 11, 13, 15, 18, 24, 26, 32, 42, 47, 49, 51, 55, 56, 58, 63, 68, 69], 'backbone.backbone.dark4.1.m.0.conv1.conv.weight': [2, 8, 12, 16, 20, 27, 44, 47, 49, 50, 51, 54, 60, 65, 67, 68, 69, 71], 'backbone.backbone.dark4.1.m.1.conv1.conv.weight': [0, 13, 16, 19, 25, 30, 31, 32, 33, 36, 39, 40, 42, 51, 53, 58, 65, 68], 'backbone.backbone.dark4.1.m.2.conv1.conv.weight': [9, 10, 16, 17, 18, 20, 23, 28, 30, 31, 43, 44, 52, 56, 59, 64, 67, 71], 'backbone.backbone.dark5.2.conv1.conv.weight': [1, 12, 20, 24, 28, 29, 30, 40, 43, 45, 49, 55, 57, 59, 60, 62, 64, 72, 75, 78, 83, 91, 92, 105, 106, 109, 112, 117, 121, 122, 123, 124, 135, 136, 138, 140], 'backbone.backbone.dark5.2.conv2.conv.weight': [3, 4, 5, 7, 9, 10, 11, 20, 21, 25, 43, 44, 46, 47, 54, 59, 65, 66, 67, 70, 74, 75, 78, 83, 88, 91, 95, 102, 103, 110, 111, 116, 123, 134, 138, 139], 'backbone.backbone.dark5.2.m.0.conv1.conv.weight': [6, 8, 11, 13, 17, 21, 24, 29, 34, 38, 39, 40, 41, 50, 59, 65, 66, 71, 75, 76, 81, 82, 83, 96, 103, 105, 106, 110, 113, 118, 120, 129, 130, 135, 140, 143], 'backbone.backbone.dark5.2.m.0.conv2.conv.weight': [8, 9, 11, 17, 19, 20, 22, 24, 26, 31, 38, 39, 41, 42, 49, 52, 55, 56, 63, 78, 81, 83, 84, 85, 88, 94, 105, 106, 107, 109, 113, 115, 121, 124, 126, 134], 'backbone.lateral_conv0.conv.weight': [10, 16, 17, 18, 32, 33, 35, 43, 51, 53, 54, 61, 63, 67, 69, 73, 74, 78, 81, 84, 85, 101, 102, 104, 107, 111, 120, 121, 133, 135, 137, 139, 140, 142, 144, 146, 155, 162, 164, 172, 175, 176, 178, 181, 182, 184, 185, 186], 'backbone.C3_p4.conv1.conv.weight': [11, 12, 15, 17, 23, 28, 35, 36, 37, 38, 40, 42, 46, 56, 58, 66, 70, 73, 82, 84, 85, 86, 88, 95], 'backbone.C3_p4.conv2.conv.weight': [0, 10, 13, 15, 16, 26, 28, 41, 44, 45, 47, 48, 57, 59, 64, 65, 66, 70, 76, 81, 85, 87, 88, 95], 'backbone.C3_p4.m.0.conv1.conv.weight': [0, 3, 6, 9, 13, 17, 21, 23, 47, 52, 53, 57, 61, 66, 67, 77, 80, 81, 82, 88, 89, 90, 92, 94], 'backbone.C3_p4.m.0.conv2.conv.weight': [2, 6, 11, 12, 19, 20, 22, 24, 27, 28, 29, 44, 57, 63, 65, 66, 67, 74, 76, 79, 80, 81, 88, 95], 'backbone.reduce_conv1.conv.weight': [0, 5, 11, 16, 20, 22, 31, 34, 40, 46, 51, 61, 63, 65, 67, 68, 73, 76, 77, 78, 79, 89, 92, 94], 'backbone.C3_p3.conv1.conv.weight': [5, 9, 12, 21, 31, 34, 35, 39, 40, 43, 45, 47], 'backbone.C3_p3.conv2.conv.weight': [2, 11, 13, 16, 17, 20, 23, 25, 30, 32, 42, 43], 'backbone.C3_p3.m.0.conv1.conv.weight': [2, 3, 9, 15, 17, 20, 24, 26, 28, 35, 38, 45], 'backbone.C3_p3.m.0.conv2.conv.weight': [0, 1, 5, 14, 19, 28, 32, 40, 42, 43, 45, 46], 'backbone.bu_conv2.conv.weight': [0, 2, 5, 12, 13, 14, 19, 22, 26, 33, 41, 43, 44, 52, 54, 56, 63, 66, 68, 72, 78, 82, 85, 87], 'backbone.C3_n3.conv1.conv.weight': [0, 3, 7, 8, 9, 17, 18, 21, 26, 32, 40, 54, 60, 64, 65, 69, 74, 82, 87, 89, 90, 91, 93, 94], 'backbone.C3_n3.conv2.conv.weight': [0, 1, 4, 5, 6, 7, 14, 27, 33, 35, 40, 41, 47, 52, 54, 67, 69, 70, 71, 74, 80, 89, 90, 92], 'backbone.C3_n3.m.0.conv1.conv.weight': [4, 8, 16, 20, 22, 28, 31, 37, 47, 51, 52, 63, 66, 67, 70, 72, 73, 74, 81, 83, 85, 88, 90, 91], 'backbone.C3_n3.m.0.conv2.conv.weight': [2, 4, 6, 10, 11, 13, 16, 19, 22, 25, 27, 31, 33, 37, 41, 53, 54, 58, 62, 68, 85, 87, 92, 95], 'backbone.bu_conv1.conv.weight': [11, 13, 14, 16, 18, 20, 26, 28, 29, 30, 40, 42, 43, 48, 49, 50, 54, 60, 64, 73, 76, 80, 83, 90, 94, 96, 100, 103, 105, 106, 117, 122, 123, 138, 140, 145, 149, 164, 166, 172, 175, 176, 179, 180, 182, 184, 188, 189], 'backbone.C3_n4.conv1.conv.weight': [5, 6, 7, 10, 13, 18, 19, 21, 26, 34, 35, 37, 38, 40, 41, 42, 48, 52, 61, 62, 66, 75, 84, 88, 93, 95, 103, 104, 110, 118, 120, 125, 130, 133, 134, 135, 137, 143, 144, 145, 147, 148, 149, 153, 169, 174, 188, 189], 'backbone.C3_n4.conv2.conv.weight': [1, 11, 13, 20, 23, 35, 37, 38, 42, 46, 47, 48, 49, 51, 52, 58, 59, 66, 75, 79, 83, 86, 88, 92, 102, 108, 109, 117, 119, 121, 125, 126, 127, 128, 129, 130, 131, 135, 139, 141, 145, 146, 151, 160, 176, 178, 180, 190], 'backbone.C3_n4.m.0.conv1.conv.weight': [2, 6, 7, 10, 12, 18, 26, 33, 36, 44, 48, 53, 55, 58, 59, 60, 61, 62, 71, 73, 74, 75, 77, 83, 85, 96, 99, 112, 122, 128, 130, 132, 135, 137, 140, 142, 144, 146, 159, 164, 171, 172, 177, 180, 181, 184, 185, 187], 'backbone.C3_n4.m.0.conv2.conv.weight': [1, 14, 16, 19, 20, 25, 32, 33, 46, 54, 58, 61, 62, 66, 67, 72, 79, 82, 84, 89, 93, 95, 97, 105, 107, 108, 111, 116, 120, 127, 129, 137, 142, 144, 145, 146, 152, 154, 164, 165, 166, 176, 180, 182, 183, 185, 186, 189], 'head.cls_convs.0.0.conv.weight': [6, 10, 11, 14, 22, 28, 30, 35, 45, 46, 47, 53, 56, 59, 62, 69, 70, 74, 77, 80, 91, 92, 94, 95], 'head.cls_convs.0.1.conv.weight': [3, 6, 12, 13, 24, 26, 35, 36, 39, 41, 44, 45, 49, 52, 59, 60, 63, 64, 67, 71, 79, 85, 89, 92], 'head.cls_convs.1.0.conv.weight': [1, 13, 16, 25, 27, 31, 34, 37, 38, 44, 49, 51, 56, 61, 62, 63, 68, 71, 77, 78, 90, 91, 93, 94], 'head.cls_convs.1.1.conv.weight': [0, 1, 3, 7, 14, 25, 26, 29, 31, 33, 38, 39, 40, 41, 47, 49, 50, 58, 59, 71, 72, 86, 87, 93], 'head.cls_convs.2.0.conv.weight': [2, 7, 15, 17, 19, 20, 21, 22, 27, 28, 29, 31, 40, 44, 45, 47, 53, 62, 70, 72, 73, 79, 85, 92], 'head.cls_convs.2.1.conv.weight': [8, 10, 11, 14, 25, 27, 28, 29, 31, 37, 40, 43, 46, 54, 56, 59, 60, 68, 74, 80, 83, 84, 91, 92], 'head.reg_convs.0.0.conv.weight': [2, 13, 23, 25, 31, 33, 34, 36, 47, 49, 53, 55, 67, 69, 72, 76, 79, 80, 81, 82, 90, 92, 93, 95], 'head.reg_convs.0.1.conv.weight': [3, 4, 16, 21, 22, 23, 26, 34, 35, 40, 41, 47, 48, 51, 56, 58, 59, 63, 64, 69, 72, 80, 82, 90], 'head.reg_convs.1.0.conv.weight': [1, 5, 11, 15, 21, 22, 23, 26, 27, 32, 39, 42, 49, 51, 65, 66, 68, 75, 76, 82, 87, 88, 91, 94], 'head.reg_convs.1.1.conv.weight': [12, 16, 17, 29, 32, 35, 38, 41, 45, 50, 51, 53, 56, 62, 69, 70, 71, 75, 77, 81, 82, 86, 88, 91], 'head.reg_convs.2.0.conv.weight': [6, 8, 9, 13, 16, 20, 24, 29, 33, 37, 41, 46, 50, 52, 53, 54, 59, 61, 70, 73, 77, 82, 87, 91], 'head.reg_convs.2.1.conv.weight': [1, 5, 11, 17, 19, 20, 21, 26, 27, 29, 32, 35, 38, 44, 52, 67, 68, 70, 72, 82, 86, 89, 94, 95]}\n"
     ]
    }
   ],
   "source": [
    "print(dict)\n",
    "#del dict['backbone.backbone.dark3.1.conv3.conv.weight'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['backbone.backbone.dark3[1].conv1.conv', 'backbone.backbone.dark3[1].conv2.conv', 'backbone.backbone.dark3[1].m[0].conv1.conv', 'backbone.backbone.dark3[1].m[1].conv1.conv', 'backbone.backbone.dark3[1].m[2].conv1.conv', 'backbone.backbone.dark4[1].conv1.conv', 'backbone.backbone.dark4[1].conv2.conv', 'backbone.backbone.dark4[1].m[0].conv1.conv', 'backbone.backbone.dark4[1].m[1].conv1.conv', 'backbone.backbone.dark4[1].m[2].conv1.conv', 'backbone.backbone.dark5[2].conv1.conv', 'backbone.backbone.dark5[2].conv2.conv', 'backbone.backbone.dark5[2].m[0].conv1.conv', 'backbone.backbone.dark5[2].m[0].conv2.conv']\n",
      "['backbone.backbone.dark3.1.conv1.conv', 'backbone.backbone.dark3.1.conv2.conv', 'backbone.backbone.dark3.1.m.0.conv1.conv', 'backbone.backbone.dark3.1.m.1.conv1.conv', 'backbone.backbone.dark3.1.m.2.conv1.conv', 'backbone.backbone.dark4.1.conv1.conv', 'backbone.backbone.dark4.1.conv2.conv', 'backbone.backbone.dark4.1.m.0.conv1.conv', 'backbone.backbone.dark4.1.m.1.conv1.conv', 'backbone.backbone.dark4.1.m.2.conv1.conv', 'backbone.backbone.dark5.2.conv1.conv', 'backbone.backbone.dark5.2.conv2.conv', 'backbone.backbone.dark5.2.m.0.conv1.conv', 'backbone.backbone.dark5.2.m.0.conv2.conv']\n",
      "['backbone.backbone.dark3[1].conv1.conv', 'backbone.backbone.dark3[1].conv2.conv', 'backbone.backbone.dark3[1].m[0].conv1.conv', 'backbone.backbone.dark3[1].m[1].conv1.conv', 'backbone.backbone.dark3[1].m[2].conv1.conv', 'backbone.backbone.dark4[1].conv1.conv', 'backbone.backbone.dark4[1].conv2.conv', 'backbone.backbone.dark4[1].m[0].conv1.conv', 'backbone.backbone.dark4[1].m[1].conv1.conv', 'backbone.backbone.dark4[1].m[2].conv1.conv', 'backbone.backbone.dark5[2].conv1.conv', 'backbone.backbone.dark5[2].conv2.conv', 'backbone.backbone.dark5[2].m[0].conv1.conv', 'backbone.backbone.dark5[2].m[0].conv2.conv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "temp = []\n",
    "temp2 = list(dict.keys())\n",
    "for i in range(len(temp2)):\n",
    "        if 'bn' in temp2[i]:\n",
    "            continue\n",
    "        if 'weight' in temp2[i]:\n",
    "            temp2[i] = temp2[i].replace('.weight','')\n",
    "            temp2[i] = temp2[i].replace('2.0','2[0]')\n",
    "            temp2[i] = temp2[i].replace('2.1','2[1]')\n",
    "            temp2[i] = temp2[i].replace('3.0','3[0]')\n",
    "            temp2[i] = temp2[i].replace('3.1','3[1]')\n",
    "            temp2[i] = temp2[i].replace('4.0','4[0]')\n",
    "            temp2[i] = temp2[i].replace('4.1','4[1]')\n",
    "            temp2[i] = temp2[i].replace('5.0','5[0]')\n",
    "            temp2[i] = temp2[i].replace('5.1','5[1]')\n",
    "            temp2[i] = temp2[i].replace('5.2','5[2]')\n",
    "            temp2[i] = temp2[i].replace('m.0','m[0]')\n",
    "            temp2[i] = temp2[i].replace('m.1','m[1]')\n",
    "            temp2[i] = temp2[i].replace('m.2','m[2]')\n",
    "            temp.append(temp2[i])\n",
    "\n",
    "\n",
    "import copy\n",
    "key = []\n",
    "temp2 = copy.deepcopy(temp)\n",
    "for i in range(len(temp2)):\n",
    "      \n",
    "            temp2[i] = temp2[i].replace('[0][0]','.0.0')\n",
    "            temp2[i] = temp2[i].replace('[0][1]','.0.1',)\n",
    "            temp2[i] = temp2[i].replace('[1][0]','.1.0',)\n",
    "            temp2[i] = temp2[i].replace('[1][1]','.1.1',)\n",
    "            temp2[i] = temp2[i].replace('[2][0]','.2.0',)\n",
    "            temp2[i] = temp2[i].replace('[2][1]','.2.1',)\n",
    "            temp2[i] = temp2[i].replace('3[0]','3.0',)\n",
    "            temp2[i] = temp2[i].replace('3[1]','3.1')\n",
    "            temp2[i] = temp2[i].replace('4[0]','4.0',)\n",
    "            temp2[i] = temp2[i].replace('4[1]','4.1',)\n",
    "            temp2[i] = temp2[i].replace('5[0]','5.0',)\n",
    "            temp2[i] = temp2[i].replace('5[1]','5.1',)\n",
    "            temp2[i] = temp2[i].replace('5[2]','5.2',)\n",
    "            temp2[i] = temp2[i].replace('m[0]','m.0',)\n",
    "            temp2[i] = temp2[i].replace('m[1]','m.1',)\n",
    "            temp2[i] = temp2[i].replace('m[2]','m.2',)\n",
    "            temp2[i] = temp2[i].replace('[0]','.0',)\n",
    "            temp2[i] = temp2[i].replace('[1]','.1',)\n",
    "            temp2[i] = temp2[i].replace('[2]','.2',)\n",
    "            key.append(temp2[i])\n",
    "\n",
    "print(key)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 22, 23, 24, 25, 26, 30, 31, 33, 37, 41, 42],\n",
       " [6, 20, 26, 29, 30, 31, 32, 34, 37, 38, 41, 46],\n",
       " [4, 11, 14, 18, 21, 27, 36, 37, 38, 40, 41, 43],\n",
       " [1, 11, 12, 16, 18, 20, 23, 24, 26, 33, 38, 42],\n",
       " [2, 12, 15, 16, 17, 27, 29, 30, 33, 34, 36, 40],\n",
       " [4,\n",
       "  9,\n",
       "  17,\n",
       "  19,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  31,\n",
       "  37,\n",
       "  46,\n",
       "  49,\n",
       "  59,\n",
       "  63,\n",
       "  64,\n",
       "  66,\n",
       "  68,\n",
       "  72,\n",
       "  75,\n",
       "  76,\n",
       "  80,\n",
       "  84,\n",
       "  85,\n",
       "  89],\n",
       " [1,\n",
       "  2,\n",
       "  9,\n",
       "  14,\n",
       "  19,\n",
       "  26,\n",
       "  35,\n",
       "  39,\n",
       "  42,\n",
       "  43,\n",
       "  45,\n",
       "  48,\n",
       "  52,\n",
       "  56,\n",
       "  63,\n",
       "  65,\n",
       "  72,\n",
       "  74,\n",
       "  75,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  92,\n",
       "  94],\n",
       " [0,\n",
       "  20,\n",
       "  22,\n",
       "  36,\n",
       "  37,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  44,\n",
       "  47,\n",
       "  49,\n",
       "  53,\n",
       "  54,\n",
       "  60,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  71,\n",
       "  72,\n",
       "  73,\n",
       "  75,\n",
       "  91,\n",
       "  93],\n",
       " [15,\n",
       "  18,\n",
       "  27,\n",
       "  29,\n",
       "  33,\n",
       "  40,\n",
       "  41,\n",
       "  43,\n",
       "  44,\n",
       "  47,\n",
       "  48,\n",
       "  50,\n",
       "  53,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  58,\n",
       "  60,\n",
       "  68,\n",
       "  84,\n",
       "  86,\n",
       "  93,\n",
       "  94,\n",
       "  95],\n",
       " [6,\n",
       "  11,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  20,\n",
       "  23,\n",
       "  27,\n",
       "  28,\n",
       "  33,\n",
       "  35,\n",
       "  38,\n",
       "  40,\n",
       "  47,\n",
       "  50,\n",
       "  55,\n",
       "  67,\n",
       "  71,\n",
       "  78,\n",
       "  84,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  92],\n",
       " [1,\n",
       "  6,\n",
       "  10,\n",
       "  11,\n",
       "  14,\n",
       "  16,\n",
       "  19,\n",
       "  21,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  32,\n",
       "  33,\n",
       "  41,\n",
       "  45,\n",
       "  50,\n",
       "  52,\n",
       "  63,\n",
       "  73,\n",
       "  74,\n",
       "  81,\n",
       "  83,\n",
       "  87,\n",
       "  90,\n",
       "  91,\n",
       "  93,\n",
       "  103,\n",
       "  104,\n",
       "  107,\n",
       "  111,\n",
       "  113,\n",
       "  114,\n",
       "  116,\n",
       "  117,\n",
       "  131,\n",
       "  132,\n",
       "  140,\n",
       "  141,\n",
       "  148,\n",
       "  154,\n",
       "  158,\n",
       "  165,\n",
       "  169,\n",
       "  172,\n",
       "  175,\n",
       "  176,\n",
       "  179,\n",
       "  187],\n",
       " [1,\n",
       "  2,\n",
       "  12,\n",
       "  13,\n",
       "  16,\n",
       "  25,\n",
       "  29,\n",
       "  30,\n",
       "  33,\n",
       "  34,\n",
       "  40,\n",
       "  45,\n",
       "  46,\n",
       "  49,\n",
       "  51,\n",
       "  55,\n",
       "  58,\n",
       "  61,\n",
       "  65,\n",
       "  67,\n",
       "  74,\n",
       "  77,\n",
       "  78,\n",
       "  89,\n",
       "  106,\n",
       "  109,\n",
       "  126,\n",
       "  127,\n",
       "  136,\n",
       "  138,\n",
       "  139,\n",
       "  142,\n",
       "  152,\n",
       "  158,\n",
       "  160,\n",
       "  161,\n",
       "  163,\n",
       "  164,\n",
       "  166,\n",
       "  168,\n",
       "  169,\n",
       "  170,\n",
       "  171,\n",
       "  173,\n",
       "  174,\n",
       "  180,\n",
       "  186,\n",
       "  188],\n",
       " [1,\n",
       "  4,\n",
       "  7,\n",
       "  10,\n",
       "  11,\n",
       "  14,\n",
       "  15,\n",
       "  25,\n",
       "  36,\n",
       "  37,\n",
       "  47,\n",
       "  51,\n",
       "  58,\n",
       "  61,\n",
       "  70,\n",
       "  75,\n",
       "  78,\n",
       "  82,\n",
       "  83,\n",
       "  85,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  97,\n",
       "  100,\n",
       "  103,\n",
       "  104,\n",
       "  105,\n",
       "  107,\n",
       "  115,\n",
       "  125,\n",
       "  126,\n",
       "  127,\n",
       "  129,\n",
       "  132,\n",
       "  136,\n",
       "  144,\n",
       "  145,\n",
       "  150,\n",
       "  156,\n",
       "  158,\n",
       "  164,\n",
       "  168,\n",
       "  169,\n",
       "  178,\n",
       "  180,\n",
       "  182,\n",
       "  184],\n",
       " [4,\n",
       "  9,\n",
       "  10,\n",
       "  18,\n",
       "  19,\n",
       "  23,\n",
       "  27,\n",
       "  31,\n",
       "  38,\n",
       "  39,\n",
       "  42,\n",
       "  43,\n",
       "  55,\n",
       "  63,\n",
       "  69,\n",
       "  71,\n",
       "  77,\n",
       "  85,\n",
       "  88,\n",
       "  90,\n",
       "  92,\n",
       "  99,\n",
       "  103,\n",
       "  109,\n",
       "  111,\n",
       "  113,\n",
       "  115,\n",
       "  119,\n",
       "  124,\n",
       "  126,\n",
       "  127,\n",
       "  130,\n",
       "  132,\n",
       "  138,\n",
       "  139,\n",
       "  148,\n",
       "  155,\n",
       "  158,\n",
       "  165,\n",
       "  169,\n",
       "  175,\n",
       "  178,\n",
       "  179,\n",
       "  180,\n",
       "  182,\n",
       "  183,\n",
       "  184,\n",
       "  190]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = list(dict.values())\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Plan\n",
      "--------------------------------\n",
      "User pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark3.1.conv1.conv (Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)) => ConvOutChannelPruner on backbone.backbone.dark3.1.conv1.conv (Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[0, 22, 23, 24, 25, 26, 30, 31, 33, 37, 41, 42], metric={'#params': 1152}]\n",
      "\n",
      "Coupled pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark3.1.conv1.conv (Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)) => BatchnormPruner on backbone.backbone.dark3.1.conv1.bn (BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)), Index=[0, 22, 23, 24, 25, 26, 30, 31, 33, 37, 41, 42], metric={'#params': 24}]\n",
      "[ [DEP] BatchnormPruner on backbone.backbone.dark3.1.conv1.bn (BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)) => ElementWiseOpPruner on _ElementWiseOp(SiluBackward0), Index=[0, 22, 23, 24, 25, 26, 30, 31, 33, 37, 41, 42], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(SiluBackward0) => ElementWiseOpPruner on _ElementWiseOp(AddBackward0), Index=[0, 22, 23, 24, 25, 26, 30, 31, 33, 37, 41, 42], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(SiluBackward0) => ConvInChannelPruner on backbone.backbone.dark3.1.m.0.conv1.conv (Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[0, 22, 23, 24, 25, 26, 30, 31, 33, 37, 41, 42], metric={'#params': 576}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(AddBackward0) => ElementWiseOpPruner on _ElementWiseOp(SiluBackward0), Index=[0, 22, 23, 24, 25, 26, 30, 31, 33, 37, 41, 42], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(AddBackward0) => ElementWiseOpPruner on _ElementWiseOp(AddBackward0), Index=[0, 22, 23, 24, 25, 26, 30, 31, 33, 37, 41, 42], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(AddBackward0) => ConvInChannelPruner on backbone.backbone.dark3.1.m.1.conv1.conv (Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[0, 22, 23, 24, 25, 26, 30, 31, 33, 37, 41, 42], metric={'#params': 576}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(AddBackward0) => ElementWiseOpPruner on _ElementWiseOp(SiluBackward0), Index=[0, 22, 23, 24, 25, 26, 30, 31, 33, 37, 41, 42], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(AddBackward0) => ElementWiseOpPruner on _ElementWiseOp(AddBackward0), Index=[0, 22, 23, 24, 25, 26, 30, 31, 33, 37, 41, 42], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(AddBackward0) => ConvInChannelPruner on backbone.backbone.dark3.1.m.2.conv1.conv (Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[0, 22, 23, 24, 25, 26, 30, 31, 33, 37, 41, 42], metric={'#params': 576}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(AddBackward0) => ElementWiseOpPruner on _ElementWiseOp(SiluBackward0), Index=[0, 22, 23, 24, 25, 26, 30, 31, 33, 37, 41, 42], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(AddBackward0) => ConcatPruner on _ConcatOp([0, 48, 96]), Index=[0, 22, 23, 24, 25, 26, 30, 31, 33, 37, 41, 42], metric={}]\n",
      "[ [DEP] ConcatPruner on _ConcatOp([0, 48, 96]) => ConvInChannelPruner on backbone.backbone.dark3.1.conv3.conv (Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[0, 22, 23, 24, 25, 26, 30, 31, 33, 37, 41, 42], metric={'#params': 1152}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(SiluBackward0) => BatchnormPruner on backbone.backbone.dark3.1.m.2.conv2.bn (BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)), Index=[0, 22, 23, 24, 25, 26, 30, 31, 33, 37, 41, 42], metric={'#params': 24}]\n",
      "[ [DEP] BatchnormPruner on backbone.backbone.dark3.1.m.2.conv2.bn (BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)) => ConvOutChannelPruner on backbone.backbone.dark3.1.m.2.conv2.conv (Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), Index=[0, 22, 23, 24, 25, 26, 30, 31, 33, 37, 41, 42], metric={'#params': 5184}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(SiluBackward0) => BatchnormPruner on backbone.backbone.dark3.1.m.1.conv2.bn (BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)), Index=[0, 22, 23, 24, 25, 26, 30, 31, 33, 37, 41, 42], metric={'#params': 24}]\n",
      "[ [DEP] BatchnormPruner on backbone.backbone.dark3.1.m.1.conv2.bn (BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)) => ConvOutChannelPruner on backbone.backbone.dark3.1.m.1.conv2.conv (Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), Index=[0, 22, 23, 24, 25, 26, 30, 31, 33, 37, 41, 42], metric={'#params': 5184}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(SiluBackward0) => BatchnormPruner on backbone.backbone.dark3.1.m.0.conv2.bn (BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)), Index=[0, 22, 23, 24, 25, 26, 30, 31, 33, 37, 41, 42], metric={'#params': 24}]\n",
      "[ [DEP] BatchnormPruner on backbone.backbone.dark3.1.m.0.conv2.bn (BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)) => ConvOutChannelPruner on backbone.backbone.dark3.1.m.0.conv2.conv (Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), Index=[0, 22, 23, 24, 25, 26, 30, 31, 33, 37, 41, 42], metric={'#params': 5184}]\n",
      "\n",
      "Metric Sum: {'#params': 19680}\n",
      "--------------------------------\n",
      "\n",
      "Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Plan\n",
      "--------------------------------\n",
      "User pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark3.1.conv2.conv (Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)) => ConvOutChannelPruner on backbone.backbone.dark3.1.conv2.conv (Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[6, 20, 26, 29, 30, 31, 32, 34, 37, 38, 41, 46], metric={'#params': 1152}]\n",
      "\n",
      "Coupled pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark3.1.conv2.conv (Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)) => BatchnormPruner on backbone.backbone.dark3.1.conv2.bn (BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)), Index=[6, 20, 26, 29, 30, 31, 32, 34, 37, 38, 41, 46], metric={'#params': 24}]\n",
      "[ [DEP] BatchnormPruner on backbone.backbone.dark3.1.conv2.bn (BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)) => ElementWiseOpPruner on _ElementWiseOp(SiluBackward0), Index=[6, 20, 26, 29, 30, 31, 32, 34, 37, 38, 41, 46], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(SiluBackward0) => ConcatPruner on _ConcatOp([0, 36, 84]), Index=[42, 56, 62, 65, 66, 67, 68, 70, 73, 74, 77, 82], metric={}]\n",
      "[ [DEP] ConcatPruner on _ConcatOp([0, 36, 84]) => ConvInChannelPruner on backbone.backbone.dark3.1.conv3.conv (Conv2d(84, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[42, 56, 62, 65, 66, 67, 68, 70, 73, 74, 77, 82], metric={'#params': 1152}]\n",
      "\n",
      "Metric Sum: {'#params': 2328}\n",
      "--------------------------------\n",
      "\n",
      "Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Plan\n",
      "--------------------------------\n",
      "User pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark3.1.m.0.conv1.conv (Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)) => ConvOutChannelPruner on backbone.backbone.dark3.1.m.0.conv1.conv (Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[4, 11, 14, 18, 21, 27, 36, 37, 38, 40, 41, 43], metric={'#params': 432}]\n",
      "\n",
      "Coupled pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark3.1.m.0.conv1.conv (Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)) => BatchnormPruner on backbone.backbone.dark3.1.m.0.conv1.bn (BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)), Index=[4, 11, 14, 18, 21, 27, 36, 37, 38, 40, 41, 43], metric={'#params': 24}]\n",
      "[ [DEP] BatchnormPruner on backbone.backbone.dark3.1.m.0.conv1.bn (BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)) => ElementWiseOpPruner on _ElementWiseOp(SiluBackward0), Index=[4, 11, 14, 18, 21, 27, 36, 37, 38, 40, 41, 43], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(SiluBackward0) => ConvInChannelPruner on backbone.backbone.dark3.1.m.0.conv2.conv (Conv2d(48, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), Index=[4, 11, 14, 18, 21, 27, 36, 37, 38, 40, 41, 43], metric={'#params': 3888}]\n",
      "\n",
      "Metric Sum: {'#params': 4344}\n",
      "--------------------------------\n",
      "\n",
      "Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Plan\n",
      "--------------------------------\n",
      "User pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark3.1.m.1.conv1.conv (Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)) => ConvOutChannelPruner on backbone.backbone.dark3.1.m.1.conv1.conv (Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[1, 11, 12, 16, 18, 20, 23, 24, 26, 33, 38, 42], metric={'#params': 432}]\n",
      "\n",
      "Coupled pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark3.1.m.1.conv1.conv (Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)) => BatchnormPruner on backbone.backbone.dark3.1.m.1.conv1.bn (BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)), Index=[1, 11, 12, 16, 18, 20, 23, 24, 26, 33, 38, 42], metric={'#params': 24}]\n",
      "[ [DEP] BatchnormPruner on backbone.backbone.dark3.1.m.1.conv1.bn (BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)) => ElementWiseOpPruner on _ElementWiseOp(SiluBackward0), Index=[1, 11, 12, 16, 18, 20, 23, 24, 26, 33, 38, 42], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(SiluBackward0) => ConvInChannelPruner on backbone.backbone.dark3.1.m.1.conv2.conv (Conv2d(48, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), Index=[1, 11, 12, 16, 18, 20, 23, 24, 26, 33, 38, 42], metric={'#params': 3888}]\n",
      "\n",
      "Metric Sum: {'#params': 4344}\n",
      "--------------------------------\n",
      "\n",
      "Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Plan\n",
      "--------------------------------\n",
      "User pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark3.1.m.2.conv1.conv (Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)) => ConvOutChannelPruner on backbone.backbone.dark3.1.m.2.conv1.conv (Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[2, 12, 15, 16, 17, 27, 29, 30, 33, 34, 36, 40], metric={'#params': 432}]\n",
      "\n",
      "Coupled pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark3.1.m.2.conv1.conv (Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)) => BatchnormPruner on backbone.backbone.dark3.1.m.2.conv1.bn (BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)), Index=[2, 12, 15, 16, 17, 27, 29, 30, 33, 34, 36, 40], metric={'#params': 24}]\n",
      "[ [DEP] BatchnormPruner on backbone.backbone.dark3.1.m.2.conv1.bn (BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)) => ElementWiseOpPruner on _ElementWiseOp(SiluBackward0), Index=[2, 12, 15, 16, 17, 27, 29, 30, 33, 34, 36, 40], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(SiluBackward0) => ConvInChannelPruner on backbone.backbone.dark3.1.m.2.conv2.conv (Conv2d(48, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), Index=[2, 12, 15, 16, 17, 27, 29, 30, 33, 34, 36, 40], metric={'#params': 3888}]\n",
      "\n",
      "Metric Sum: {'#params': 4344}\n",
      "--------------------------------\n",
      "\n",
      "Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Plan\n",
      "--------------------------------\n",
      "User pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark4.1.conv1.conv (Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)) => ConvOutChannelPruner on backbone.backbone.dark4.1.conv1.conv (Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[4, 9, 17, 19, 23, 24, 25, 26, 31, 37, 46, 49, 59, 63, 64, 66, 68, 72, 75, 76, 80, 84, 85, 89], metric={'#params': 4608}]\n",
      "\n",
      "Coupled pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark4.1.conv1.conv (Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)) => BatchnormPruner on backbone.backbone.dark4.1.conv1.bn (BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)), Index=[4, 9, 17, 19, 23, 24, 25, 26, 31, 37, 46, 49, 59, 63, 64, 66, 68, 72, 75, 76, 80, 84, 85, 89], metric={'#params': 48}]\n",
      "[ [DEP] BatchnormPruner on backbone.backbone.dark4.1.conv1.bn (BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)) => ElementWiseOpPruner on _ElementWiseOp(SiluBackward0), Index=[4, 9, 17, 19, 23, 24, 25, 26, 31, 37, 46, 49, 59, 63, 64, 66, 68, 72, 75, 76, 80, 84, 85, 89], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(SiluBackward0) => ElementWiseOpPruner on _ElementWiseOp(AddBackward0), Index=[4, 9, 17, 19, 23, 24, 25, 26, 31, 37, 46, 49, 59, 63, 64, 66, 68, 72, 75, 76, 80, 84, 85, 89], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(SiluBackward0) => ConvInChannelPruner on backbone.backbone.dark4.1.m.0.conv1.conv (Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[4, 9, 17, 19, 23, 24, 25, 26, 31, 37, 46, 49, 59, 63, 64, 66, 68, 72, 75, 76, 80, 84, 85, 89], metric={'#params': 2304}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(AddBackward0) => ElementWiseOpPruner on _ElementWiseOp(SiluBackward0), Index=[4, 9, 17, 19, 23, 24, 25, 26, 31, 37, 46, 49, 59, 63, 64, 66, 68, 72, 75, 76, 80, 84, 85, 89], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(AddBackward0) => ElementWiseOpPruner on _ElementWiseOp(AddBackward0), Index=[4, 9, 17, 19, 23, 24, 25, 26, 31, 37, 46, 49, 59, 63, 64, 66, 68, 72, 75, 76, 80, 84, 85, 89], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(AddBackward0) => ConvInChannelPruner on backbone.backbone.dark4.1.m.1.conv1.conv (Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[4, 9, 17, 19, 23, 24, 25, 26, 31, 37, 46, 49, 59, 63, 64, 66, 68, 72, 75, 76, 80, 84, 85, 89], metric={'#params': 2304}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(AddBackward0) => ElementWiseOpPruner on _ElementWiseOp(SiluBackward0), Index=[4, 9, 17, 19, 23, 24, 25, 26, 31, 37, 46, 49, 59, 63, 64, 66, 68, 72, 75, 76, 80, 84, 85, 89], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(AddBackward0) => ElementWiseOpPruner on _ElementWiseOp(AddBackward0), Index=[4, 9, 17, 19, 23, 24, 25, 26, 31, 37, 46, 49, 59, 63, 64, 66, 68, 72, 75, 76, 80, 84, 85, 89], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(AddBackward0) => ConvInChannelPruner on backbone.backbone.dark4.1.m.2.conv1.conv (Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[4, 9, 17, 19, 23, 24, 25, 26, 31, 37, 46, 49, 59, 63, 64, 66, 68, 72, 75, 76, 80, 84, 85, 89], metric={'#params': 2304}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(AddBackward0) => ElementWiseOpPruner on _ElementWiseOp(SiluBackward0), Index=[4, 9, 17, 19, 23, 24, 25, 26, 31, 37, 46, 49, 59, 63, 64, 66, 68, 72, 75, 76, 80, 84, 85, 89], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(AddBackward0) => ConcatPruner on _ConcatOp([0, 96, 192]), Index=[4, 9, 17, 19, 23, 24, 25, 26, 31, 37, 46, 49, 59, 63, 64, 66, 68, 72, 75, 76, 80, 84, 85, 89], metric={}]\n",
      "[ [DEP] ConcatPruner on _ConcatOp([0, 96, 192]) => ConvInChannelPruner on backbone.backbone.dark4.1.conv3.conv (Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[4, 9, 17, 19, 23, 24, 25, 26, 31, 37, 46, 49, 59, 63, 64, 66, 68, 72, 75, 76, 80, 84, 85, 89], metric={'#params': 4608}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(SiluBackward0) => BatchnormPruner on backbone.backbone.dark4.1.m.2.conv2.bn (BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)), Index=[4, 9, 17, 19, 23, 24, 25, 26, 31, 37, 46, 49, 59, 63, 64, 66, 68, 72, 75, 76, 80, 84, 85, 89], metric={'#params': 48}]\n",
      "[ [DEP] BatchnormPruner on backbone.backbone.dark4.1.m.2.conv2.bn (BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)) => ConvOutChannelPruner on backbone.backbone.dark4.1.m.2.conv2.conv (Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), Index=[4, 9, 17, 19, 23, 24, 25, 26, 31, 37, 46, 49, 59, 63, 64, 66, 68, 72, 75, 76, 80, 84, 85, 89], metric={'#params': 20736}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(SiluBackward0) => BatchnormPruner on backbone.backbone.dark4.1.m.1.conv2.bn (BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)), Index=[4, 9, 17, 19, 23, 24, 25, 26, 31, 37, 46, 49, 59, 63, 64, 66, 68, 72, 75, 76, 80, 84, 85, 89], metric={'#params': 48}]\n",
      "[ [DEP] BatchnormPruner on backbone.backbone.dark4.1.m.1.conv2.bn (BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)) => ConvOutChannelPruner on backbone.backbone.dark4.1.m.1.conv2.conv (Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), Index=[4, 9, 17, 19, 23, 24, 25, 26, 31, 37, 46, 49, 59, 63, 64, 66, 68, 72, 75, 76, 80, 84, 85, 89], metric={'#params': 20736}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(SiluBackward0) => BatchnormPruner on backbone.backbone.dark4.1.m.0.conv2.bn (BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)), Index=[4, 9, 17, 19, 23, 24, 25, 26, 31, 37, 46, 49, 59, 63, 64, 66, 68, 72, 75, 76, 80, 84, 85, 89], metric={'#params': 48}]\n",
      "[ [DEP] BatchnormPruner on backbone.backbone.dark4.1.m.0.conv2.bn (BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)) => ConvOutChannelPruner on backbone.backbone.dark4.1.m.0.conv2.conv (Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), Index=[4, 9, 17, 19, 23, 24, 25, 26, 31, 37, 46, 49, 59, 63, 64, 66, 68, 72, 75, 76, 80, 84, 85, 89], metric={'#params': 20736}]\n",
      "\n",
      "Metric Sum: {'#params': 78528}\n",
      "--------------------------------\n",
      "\n",
      "Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Plan\n",
      "--------------------------------\n",
      "User pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark4.1.conv2.conv (Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)) => ConvOutChannelPruner on backbone.backbone.dark4.1.conv2.conv (Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[1, 2, 9, 14, 19, 26, 35, 39, 42, 43, 45, 48, 52, 56, 63, 65, 72, 74, 75, 84, 85, 86, 92, 94], metric={'#params': 4608}]\n",
      "\n",
      "Coupled pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark4.1.conv2.conv (Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)) => BatchnormPruner on backbone.backbone.dark4.1.conv2.bn (BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)), Index=[1, 2, 9, 14, 19, 26, 35, 39, 42, 43, 45, 48, 52, 56, 63, 65, 72, 74, 75, 84, 85, 86, 92, 94], metric={'#params': 48}]\n",
      "[ [DEP] BatchnormPruner on backbone.backbone.dark4.1.conv2.bn (BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)) => ElementWiseOpPruner on _ElementWiseOp(SiluBackward0), Index=[1, 2, 9, 14, 19, 26, 35, 39, 42, 43, 45, 48, 52, 56, 63, 65, 72, 74, 75, 84, 85, 86, 92, 94], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(SiluBackward0) => ConcatPruner on _ConcatOp([0, 72, 168]), Index=[73, 74, 81, 86, 91, 98, 107, 111, 114, 115, 117, 120, 124, 128, 135, 137, 144, 146, 147, 156, 157, 158, 164, 166], metric={}]\n",
      "[ [DEP] ConcatPruner on _ConcatOp([0, 72, 168]) => ConvInChannelPruner on backbone.backbone.dark4.1.conv3.conv (Conv2d(168, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[73, 74, 81, 86, 91, 98, 107, 111, 114, 115, 117, 120, 124, 128, 135, 137, 144, 146, 147, 156, 157, 158, 164, 166], metric={'#params': 4608}]\n",
      "\n",
      "Metric Sum: {'#params': 9264}\n",
      "--------------------------------\n",
      "\n",
      "Conv2d(72, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Plan\n",
      "--------------------------------\n",
      "User pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark4.1.m.0.conv1.conv (Conv2d(72, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)) => ConvOutChannelPruner on backbone.backbone.dark4.1.m.0.conv1.conv (Conv2d(72, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[0, 20, 22, 36, 37, 39, 40, 41, 44, 47, 49, 53, 54, 60, 61, 62, 63, 64, 71, 72, 73, 75, 91, 93], metric={'#params': 1728}]\n",
      "\n",
      "Coupled pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark4.1.m.0.conv1.conv (Conv2d(72, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)) => BatchnormPruner on backbone.backbone.dark4.1.m.0.conv1.bn (BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)), Index=[0, 20, 22, 36, 37, 39, 40, 41, 44, 47, 49, 53, 54, 60, 61, 62, 63, 64, 71, 72, 73, 75, 91, 93], metric={'#params': 48}]\n",
      "[ [DEP] BatchnormPruner on backbone.backbone.dark4.1.m.0.conv1.bn (BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)) => ElementWiseOpPruner on _ElementWiseOp(SiluBackward0), Index=[0, 20, 22, 36, 37, 39, 40, 41, 44, 47, 49, 53, 54, 60, 61, 62, 63, 64, 71, 72, 73, 75, 91, 93], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(SiluBackward0) => ConvInChannelPruner on backbone.backbone.dark4.1.m.0.conv2.conv (Conv2d(96, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), Index=[0, 20, 22, 36, 37, 39, 40, 41, 44, 47, 49, 53, 54, 60, 61, 62, 63, 64, 71, 72, 73, 75, 91, 93], metric={'#params': 15552}]\n",
      "\n",
      "Metric Sum: {'#params': 17328}\n",
      "--------------------------------\n",
      "\n",
      "Conv2d(72, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Plan\n",
      "--------------------------------\n",
      "User pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark4.1.m.1.conv1.conv (Conv2d(72, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)) => ConvOutChannelPruner on backbone.backbone.dark4.1.m.1.conv1.conv (Conv2d(72, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[15, 18, 27, 29, 33, 40, 41, 43, 44, 47, 48, 50, 53, 54, 55, 56, 58, 60, 68, 84, 86, 93, 94, 95], metric={'#params': 1728}]\n",
      "\n",
      "Coupled pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark4.1.m.1.conv1.conv (Conv2d(72, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)) => BatchnormPruner on backbone.backbone.dark4.1.m.1.conv1.bn (BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)), Index=[15, 18, 27, 29, 33, 40, 41, 43, 44, 47, 48, 50, 53, 54, 55, 56, 58, 60, 68, 84, 86, 93, 94, 95], metric={'#params': 48}]\n",
      "[ [DEP] BatchnormPruner on backbone.backbone.dark4.1.m.1.conv1.bn (BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)) => ElementWiseOpPruner on _ElementWiseOp(SiluBackward0), Index=[15, 18, 27, 29, 33, 40, 41, 43, 44, 47, 48, 50, 53, 54, 55, 56, 58, 60, 68, 84, 86, 93, 94, 95], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(SiluBackward0) => ConvInChannelPruner on backbone.backbone.dark4.1.m.1.conv2.conv (Conv2d(96, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), Index=[15, 18, 27, 29, 33, 40, 41, 43, 44, 47, 48, 50, 53, 54, 55, 56, 58, 60, 68, 84, 86, 93, 94, 95], metric={'#params': 15552}]\n",
      "\n",
      "Metric Sum: {'#params': 17328}\n",
      "--------------------------------\n",
      "\n",
      "Conv2d(72, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Plan\n",
      "--------------------------------\n",
      "User pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark4.1.m.2.conv1.conv (Conv2d(72, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)) => ConvOutChannelPruner on backbone.backbone.dark4.1.m.2.conv1.conv (Conv2d(72, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[6, 11, 16, 17, 18, 20, 23, 27, 28, 33, 35, 38, 40, 47, 50, 55, 67, 71, 78, 84, 88, 89, 90, 92], metric={'#params': 1728}]\n",
      "\n",
      "Coupled pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark4.1.m.2.conv1.conv (Conv2d(72, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)) => BatchnormPruner on backbone.backbone.dark4.1.m.2.conv1.bn (BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)), Index=[6, 11, 16, 17, 18, 20, 23, 27, 28, 33, 35, 38, 40, 47, 50, 55, 67, 71, 78, 84, 88, 89, 90, 92], metric={'#params': 48}]\n",
      "[ [DEP] BatchnormPruner on backbone.backbone.dark4.1.m.2.conv1.bn (BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)) => ElementWiseOpPruner on _ElementWiseOp(SiluBackward0), Index=[6, 11, 16, 17, 18, 20, 23, 27, 28, 33, 35, 38, 40, 47, 50, 55, 67, 71, 78, 84, 88, 89, 90, 92], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(SiluBackward0) => ConvInChannelPruner on backbone.backbone.dark4.1.m.2.conv2.conv (Conv2d(96, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), Index=[6, 11, 16, 17, 18, 20, 23, 27, 28, 33, 35, 38, 40, 47, 50, 55, 67, 71, 78, 84, 88, 89, 90, 92], metric={'#params': 15552}]\n",
      "\n",
      "Metric Sum: {'#params': 17328}\n",
      "--------------------------------\n",
      "\n",
      "Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Plan\n",
      "--------------------------------\n",
      "User pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark5.2.conv1.conv (Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)) => ConvOutChannelPruner on backbone.backbone.dark5.2.conv1.conv (Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[1, 6, 10, 11, 14, 16, 19, 21, 28, 29, 30, 32, 33, 41, 45, 50, 52, 63, 73, 74, 81, 83, 87, 90, 91, 93, 103, 104, 107, 111, 113, 114, 116, 117, 131, 132, 140, 141, 148, 154, 158, 165, 169, 172, 175, 176, 179, 187], metric={'#params': 18432}]\n",
      "\n",
      "Coupled pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark5.2.conv1.conv (Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)) => BatchnormPruner on backbone.backbone.dark5.2.conv1.bn (BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)), Index=[1, 6, 10, 11, 14, 16, 19, 21, 28, 29, 30, 32, 33, 41, 45, 50, 52, 63, 73, 74, 81, 83, 87, 90, 91, 93, 103, 104, 107, 111, 113, 114, 116, 117, 131, 132, 140, 141, 148, 154, 158, 165, 169, 172, 175, 176, 179, 187], metric={'#params': 96}]\n",
      "[ [DEP] BatchnormPruner on backbone.backbone.dark5.2.conv1.bn (BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)) => ElementWiseOpPruner on _ElementWiseOp(SiluBackward0), Index=[1, 6, 10, 11, 14, 16, 19, 21, 28, 29, 30, 32, 33, 41, 45, 50, 52, 63, 73, 74, 81, 83, 87, 90, 91, 93, 103, 104, 107, 111, 113, 114, 116, 117, 131, 132, 140, 141, 148, 154, 158, 165, 169, 172, 175, 176, 179, 187], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(SiluBackward0) => ConvInChannelPruner on backbone.backbone.dark5.2.m.0.conv1.conv (Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[1, 6, 10, 11, 14, 16, 19, 21, 28, 29, 30, 32, 33, 41, 45, 50, 52, 63, 73, 74, 81, 83, 87, 90, 91, 93, 103, 104, 107, 111, 113, 114, 116, 117, 131, 132, 140, 141, 148, 154, 158, 165, 169, 172, 175, 176, 179, 187], metric={'#params': 9216}]\n",
      "\n",
      "Metric Sum: {'#params': 27744}\n",
      "--------------------------------\n",
      "\n",
      "Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Plan\n",
      "--------------------------------\n",
      "User pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark5.2.conv2.conv (Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)) => ConvOutChannelPruner on backbone.backbone.dark5.2.conv2.conv (Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[1, 2, 12, 13, 16, 25, 29, 30, 33, 34, 40, 45, 46, 49, 51, 55, 58, 61, 65, 67, 74, 77, 78, 89, 106, 109, 126, 127, 136, 138, 139, 142, 152, 158, 160, 161, 163, 164, 166, 168, 169, 170, 171, 173, 174, 180, 186, 188], metric={'#params': 18432}]\n",
      "\n",
      "Coupled pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark5.2.conv2.conv (Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)) => BatchnormPruner on backbone.backbone.dark5.2.conv2.bn (BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)), Index=[1, 2, 12, 13, 16, 25, 29, 30, 33, 34, 40, 45, 46, 49, 51, 55, 58, 61, 65, 67, 74, 77, 78, 89, 106, 109, 126, 127, 136, 138, 139, 142, 152, 158, 160, 161, 163, 164, 166, 168, 169, 170, 171, 173, 174, 180, 186, 188], metric={'#params': 96}]\n",
      "[ [DEP] BatchnormPruner on backbone.backbone.dark5.2.conv2.bn (BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)) => ElementWiseOpPruner on _ElementWiseOp(SiluBackward0), Index=[1, 2, 12, 13, 16, 25, 29, 30, 33, 34, 40, 45, 46, 49, 51, 55, 58, 61, 65, 67, 74, 77, 78, 89, 106, 109, 126, 127, 136, 138, 139, 142, 152, 158, 160, 161, 163, 164, 166, 168, 169, 170, 171, 173, 174, 180, 186, 188], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(SiluBackward0) => ConcatPruner on _ConcatOp([0, 192, 384]), Index=[193, 194, 204, 205, 208, 217, 221, 222, 225, 226, 232, 237, 238, 241, 243, 247, 250, 253, 257, 259, 266, 269, 270, 281, 298, 301, 318, 319, 328, 330, 331, 334, 344, 350, 352, 353, 355, 356, 358, 360, 361, 362, 363, 365, 366, 372, 378, 380], metric={}]\n",
      "[ [DEP] ConcatPruner on _ConcatOp([0, 192, 384]) => ConvInChannelPruner on backbone.backbone.dark5.2.conv3.conv (Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[193, 194, 204, 205, 208, 217, 221, 222, 225, 226, 232, 237, 238, 241, 243, 247, 250, 253, 257, 259, 266, 269, 270, 281, 298, 301, 318, 319, 328, 330, 331, 334, 344, 350, 352, 353, 355, 356, 358, 360, 361, 362, 363, 365, 366, 372, 378, 380], metric={'#params': 18432}]\n",
      "\n",
      "Metric Sum: {'#params': 36960}\n",
      "--------------------------------\n",
      "\n",
      "Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Plan\n",
      "--------------------------------\n",
      "User pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark5.2.m.0.conv1.conv (Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)) => ConvOutChannelPruner on backbone.backbone.dark5.2.m.0.conv1.conv (Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[1, 4, 7, 10, 11, 14, 15, 25, 36, 37, 47, 51, 58, 61, 70, 75, 78, 82, 83, 85, 88, 89, 90, 97, 100, 103, 104, 105, 107, 115, 125, 126, 127, 129, 132, 136, 144, 145, 150, 156, 158, 164, 168, 169, 178, 180, 182, 184], metric={'#params': 6912}]\n",
      "\n",
      "Coupled pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark5.2.m.0.conv1.conv (Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)) => BatchnormPruner on backbone.backbone.dark5.2.m.0.conv1.bn (BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)), Index=[1, 4, 7, 10, 11, 14, 15, 25, 36, 37, 47, 51, 58, 61, 70, 75, 78, 82, 83, 85, 88, 89, 90, 97, 100, 103, 104, 105, 107, 115, 125, 126, 127, 129, 132, 136, 144, 145, 150, 156, 158, 164, 168, 169, 178, 180, 182, 184], metric={'#params': 96}]\n",
      "[ [DEP] BatchnormPruner on backbone.backbone.dark5.2.m.0.conv1.bn (BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)) => ElementWiseOpPruner on _ElementWiseOp(SiluBackward0), Index=[1, 4, 7, 10, 11, 14, 15, 25, 36, 37, 47, 51, 58, 61, 70, 75, 78, 82, 83, 85, 88, 89, 90, 97, 100, 103, 104, 105, 107, 115, 125, 126, 127, 129, 132, 136, 144, 145, 150, 156, 158, 164, 168, 169, 178, 180, 182, 184], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(SiluBackward0) => ConvInChannelPruner on backbone.backbone.dark5.2.m.0.conv2.conv (Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), Index=[1, 4, 7, 10, 11, 14, 15, 25, 36, 37, 47, 51, 58, 61, 70, 75, 78, 82, 83, 85, 88, 89, 90, 97, 100, 103, 104, 105, 107, 115, 125, 126, 127, 129, 132, 136, 144, 145, 150, 156, 158, 164, 168, 169, 178, 180, 182, 184], metric={'#params': 82944}]\n",
      "\n",
      "Metric Sum: {'#params': 89952}\n",
      "--------------------------------\n",
      "\n",
      "Conv2d(144, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Plan\n",
      "--------------------------------\n",
      "User pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark5.2.m.0.conv2.conv (Conv2d(144, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)) => ConvOutChannelPruner on backbone.backbone.dark5.2.m.0.conv2.conv (Conv2d(144, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), Index=[4, 9, 10, 18, 19, 23, 27, 31, 38, 39, 42, 43, 55, 63, 69, 71, 77, 85, 88, 90, 92, 99, 103, 109, 111, 113, 115, 119, 124, 126, 127, 130, 132, 138, 139, 148, 155, 158, 165, 169, 175, 178, 179, 180, 182, 183, 184, 190], metric={'#params': 62208}]\n",
      "\n",
      "Coupled pruning:\n",
      "[ [DEP] ConvOutChannelPruner on backbone.backbone.dark5.2.m.0.conv2.conv (Conv2d(144, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)) => BatchnormPruner on backbone.backbone.dark5.2.m.0.conv2.bn (BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)), Index=[4, 9, 10, 18, 19, 23, 27, 31, 38, 39, 42, 43, 55, 63, 69, 71, 77, 85, 88, 90, 92, 99, 103, 109, 111, 113, 115, 119, 124, 126, 127, 130, 132, 138, 139, 148, 155, 158, 165, 169, 175, 178, 179, 180, 182, 183, 184, 190], metric={'#params': 96}]\n",
      "[ [DEP] BatchnormPruner on backbone.backbone.dark5.2.m.0.conv2.bn (BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)) => ElementWiseOpPruner on _ElementWiseOp(SiluBackward0), Index=[4, 9, 10, 18, 19, 23, 27, 31, 38, 39, 42, 43, 55, 63, 69, 71, 77, 85, 88, 90, 92, 99, 103, 109, 111, 113, 115, 119, 124, 126, 127, 130, 132, 138, 139, 148, 155, 158, 165, 169, 175, 178, 179, 180, 182, 183, 184, 190], metric={}]\n",
      "[ [DEP] ElementWiseOpPruner on _ElementWiseOp(SiluBackward0) => ConcatPruner on _ConcatOp([0, 192, 336]), Index=[4, 9, 10, 18, 19, 23, 27, 31, 38, 39, 42, 43, 55, 63, 69, 71, 77, 85, 88, 90, 92, 99, 103, 109, 111, 113, 115, 119, 124, 126, 127, 130, 132, 138, 139, 148, 155, 158, 165, 169, 175, 178, 179, 180, 182, 183, 184, 190], metric={}]\n",
      "[ [DEP] ConcatPruner on _ConcatOp([0, 192, 336]) => ConvInChannelPruner on backbone.backbone.dark5.2.conv3.conv (Conv2d(336, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)), Index=[4, 9, 10, 18, 19, 23, 27, 31, 38, 39, 42, 43, 55, 63, 69, 71, 77, 85, 88, 90, 92, 99, 103, 109, 111, 113, 115, 119, 124, 126, 127, 130, 132, 138, 139, 148, 155, 158, 165, 169, 175, 178, 179, 180, 182, 183, 184, 190], metric={'#params': 18432}]\n",
      "\n",
      "Metric Sum: {'#params': 80736}\n",
      "--------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(temp)):\n",
    "    #pruning_plan = DG.get_pruning_plan(eval(f\"model.{temp[i]}\"), tp.prune_conv_out_channel, value[i])\n",
    "    pruning_plan = DG.get_pruning_plan(eval(f\"model.{temp[i]}\"), tp.prune_conv_out_channel, dict[(key[i]) + '.weight'])\n",
    "    print(pruning_plan)\n",
    "    if DG.check_pruning_plan(pruning_plan):\n",
    "        pruning_plan.exec()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOX(\n",
      "  (backbone): YOLOPAFPN(\n",
      "    (backbone): CSPDarknet(\n",
      "      (stem): Focus(\n",
      "        (conv): BaseConv(\n",
      "          (conv): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (dark2): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(24, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): CSPLayer(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv3): BaseConv(\n",
      "            (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dark3): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): CSPLayer(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(96, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(36, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(96, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(36, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv3): BaseConv(\n",
      "            (conv): Conv2d(72, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(36, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(36, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (1): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(36, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(36, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (2): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(36, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(36, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dark4): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): CSPLayer(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(192, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(192, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv3): BaseConv(\n",
      "            (conv): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (1): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (2): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dark5): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): SPPBottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): ModuleList(\n",
      "            (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "            (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
      "            (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): CSPLayer(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(384, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(384, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv3): BaseConv(\n",
      "            (conv): Conv2d(288, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(144, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(144, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(144, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
      "    (lateral_conv0): BaseConv(\n",
      "      (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (C3_p4): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (reduce_conv1): BaseConv(\n",
      "      (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (C3_p3): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bu_conv2): BaseConv(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (C3_n3): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bu_conv1): BaseConv(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (C3_n4): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): YOLOXHead(\n",
      "    (cls_convs): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (reg_convs): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cls_preds): ModuleList(\n",
      "      (0): Conv2d(96, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(96, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): Conv2d(96, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (reg_preds): ModuleList(\n",
      "      (0): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (obj_preds): ModuleList(\n",
      "      (0): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (stems): ModuleList(\n",
      "      (0): BaseConv(\n",
      "        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): BaseConv(\n",
      "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): BaseConv(\n",
      "        (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (l1_loss): L1Loss()\n",
      "    (bcewithlog_loss): BCEWithLogitsLoss()\n",
      "    (iou_loss): IOUloss()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_state = {\n",
    "                \"model\": model.state_dict(),\n",
    "            }\n",
    "\n",
    "torch.save(ckpt_state, 'type3_0.25_b_v2.pth')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
